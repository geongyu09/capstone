# ê°„ë‹¨ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ - run_training.py
from csi_fall_detection import CSIFallDetection
import numpy as np
from sklearn.model_selection import train_test_split
import os
import glob

def main():
    print("ğŸš€ CSI ë‚™ìƒ ê°ì§€ ëª¨ë¸ í•™ìŠµ ì‹œì‘!")
    print("=" * 50)
    
    # í´ë” í™•ì¸
    data_dir = "./csi_data"
    if not os.path.exists(data_dir):
        print(f"âŒ ì˜¤ë¥˜: {data_dir} í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤!")
        print("ë‹¤ìŒê³¼ ê°™ì´ í´ë”ë¥¼ ë§Œë“¤ê³  CSV íŒŒì¼ë“¤ì„ ë„£ì–´ì£¼ì„¸ìš”:")
        print("mkdir csi_data")
        print("# ê·¸ ë‹¤ìŒ CSV íŒŒì¼ë“¤ì„ csi_data í´ë”ì— ë³µì‚¬")
        return
    
    # CSV íŒŒì¼ ê°œìˆ˜ í™•ì¸ (ì¬ê·€ ê²€ìƒ‰ í¬í•¨)
    csv_files = glob.glob(os.path.join(data_dir, "**", "*.csv"), recursive=True)
    print(f"ğŸ“ ë°œê²¬ëœ CSV íŒŒì¼ ìˆ˜: {len(csv_files)}")
    
    if len(csv_files) == 0:
        print("âŒ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤! csi_data í´ë”ì— CSV íŒŒì¼ë“¤ì„ ë„£ì–´ì£¼ì„¸ìš”.")
        print("   í˜¹ì‹œ í•˜ìœ„ í´ë”ì— íŒŒì¼ì´ ìˆë‹¤ë©´ ì¬ê·€ ê²€ìƒ‰ì´ í™œì„±í™”ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return
    
    # ë°œê²¬ëœ íŒŒì¼ë“¤ ì¶œë ¥
    print("ë°œê²¬ëœ íŒŒì¼ë“¤:")
    for file_path in csv_files[:10]:  # ì²˜ìŒ 10ê°œë§Œ ì¶œë ¥
        relative_path = os.path.relpath(file_path, data_dir)
        print(f"  - {relative_path}")
    if len(csv_files) > 10:
        print(f"  ... ê·¸ ì™¸ {len(csv_files) - 10}ê°œ íŒŒì¼")
    
    # 1. ëª¨ë¸ ì´ˆê¸°í™”
    print("\n1ï¸âƒ£ ëª¨ë¸ ì´ˆê¸°í™”...")
    detector = CSIFallDetection(window_size=50, stride=1)
    
    try:
        # 2. ë°ì´í„° ë¡œë“œ
        print("\n2ï¸âƒ£ ë°ì´í„° ë¡œë“œ ì¤‘...")
        print("   ğŸ“ í•˜ìœ„ í´ë”ê¹Œì§€ ì¬ê·€ì ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤...")
        X, y, timestamps = detector.load_csv_files(data_dir, recursive=True)
        
        # ë¼ë²¨ ë¶„í¬ í™•ì¸
        fall_count = np.sum(y == 1)
        normal_count = np.sum(y == 0)
        
        if fall_count == 0:
            print("âš ï¸  ê²½ê³ : ë‚™ìƒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤! ì¼ë¶€ CSV íŒŒì¼ì˜ labelì„ 1ë¡œ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        
        if normal_count == 0:
            print("âš ï¸  ê²½ê³ : ì •ìƒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤! ì¼ë¶€ CSV íŒŒì¼ì˜ labelì„ 0ìœ¼ë¡œ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        
        # 3. ì‹œí€€ìŠ¤ ìƒì„±
        print("\n3ï¸âƒ£ ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ìƒì„± ì¤‘...")
        X_seq, y_seq = detector.create_sequences(X, y)
        
        # 4. ë°ì´í„° ì „ì²˜ë¦¬
        print("\n4ï¸âƒ£ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
        X_seq = detector.preprocess_data(X_seq, feature_selection=True)
        
        # 5. ë°ì´í„° ë¶„í•  (ë¼ë²¨ì´ í•œ ì¢…ë¥˜ë§Œ ìˆìœ¼ë©´ stratify ì œê±°)
        print("\n5ï¸âƒ£ í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• ...")
        
        if len(np.unique(y_seq)) > 1:  # ë¼ë²¨ì´ 2ì¢…ë¥˜ ì´ìƒ
            X_train, X_test, y_train, y_test = train_test_split(
                X_seq, y_seq, 
                test_size=0.2, 
                stratify=y_seq,
                random_state=42
            )
            print("   âœ… ê³„ì¸µ ë¶„í• (stratify) ì ìš©")
        else:  # ë¼ë²¨ì´ 1ì¢…ë¥˜ë¿
            print("   âš ï¸  ë¼ë²¨ì´ í•œ ì¢…ë¥˜ë¿ì…ë‹ˆë‹¤. stratify ì—†ì´ ë¶„í• í•©ë‹ˆë‹¤.")
            X_train, X_test, y_train, y_test = train_test_split(
                X_seq, y_seq, 
                test_size=0.2, 
                random_state=42
            )
        
        print(f"   - í›ˆë ¨ ì„¸íŠ¸: {X_train.shape}")
        print(f"   - í…ŒìŠ¤íŠ¸ ì„¸íŠ¸: {X_test.shape}")
        print(f"   - í›ˆë ¨ ë¼ë²¨ ë¶„í¬: {dict(zip(*np.unique(y_train, return_counts=True)))}")
        print(f"   - í…ŒìŠ¤íŠ¸ ë¼ë²¨ ë¶„í¬: {dict(zip(*np.unique(y_test, return_counts=True)))}")
        
        # 6. ëª¨ë¸ êµ¬ì¶•
        print("\n6ï¸âƒ£ ëª¨ë¸ êµ¬ì¶• ì¤‘...")
        input_shape = (X_train.shape[1], X_train.shape[2])
        
        # íŠ¹ì§• ìˆ˜ì— ë”°ë¼ ëª¨ë¸ íƒ€ì… ìë™ ì„ íƒ
        if X_train.shape[2] > 100:
            model_type = 'lightweight'
            print(f"   ğŸ’¡ íŠ¹ì§• ìˆ˜ê°€ ë§ì•„ ê²½ëŸ‰ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ({X_train.shape[2]}ê°œ íŠ¹ì§•)")
        else:
            model_type = 'standard'
            print(f"   ğŸ’¡ í‘œì¤€ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ({X_train.shape[2]}ê°œ íŠ¹ì§•)")
        
        detector.build_model(input_shape, model_type=model_type)
        
        # 7. ëª¨ë¸ í•™ìŠµ
        print("\n7ï¸âƒ£ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
        print("   (í•™ìŠµ ì¤‘ì—ëŠ” progress barê°€ í‘œì‹œë©ë‹ˆë‹¤)")
        
        epochs = 150 if X_train.shape[2] > 100 else 100
        batch_size = 16 if X_train.shape[2] > 100 else 32
        
        print(f"   - ì—í¬í¬: {epochs}")
        print(f"   - ë°°ì¹˜ í¬ê¸°: {batch_size}")
        print(f"   - ëª¨ë¸ íƒ€ì…: {model_type}")
        
        history = detector.train_model(
            X_train, y_train, 
            epochs=epochs, 
            batch_size=batch_size
        )
        
        # 8. ëª¨ë¸ í‰ê°€
        print("\n8ï¸âƒ£ ëª¨ë¸ í‰ê°€ ì¤‘...")
        y_pred_prob, y_pred = detector.evaluate_model(X_test, y_test)
        
        # 9. ëª¨ë¸ ì €ì¥
        print("\n9ï¸âƒ£ ëª¨ë¸ ì €ì¥ ì¤‘...")
        os.makedirs('./models', exist_ok=True)
        model_name = f'./models/csi_fall_detection_{X_train.shape[2]}features.h5'
        detector.model.save(model_name)
        
        print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_name}")
        print(f"âœ… í•™ìŠµ ì™„ë£Œ!")
        
        # ê²°ê³¼ ìš”ì•½
        print("\n" + "=" * 50)
        print("ğŸ“‹ í•™ìŠµ ê²°ê³¼ ìš”ì•½:")
        print(f"   - ì‚¬ìš©ëœ CSV íŒŒì¼: {len(csv_files)}ê°œ")
        print(f"   - ì´ ë°ì´í„° í¬ì¸íŠ¸: {X.shape[0]:,}ê°œ")
        print(f"   - ìƒì„±ëœ ì‹œí€€ìŠ¤: {X_seq.shape[0]:,}ê°œ")
        print(f"   - íŠ¹ì§• ìˆ˜: {X_train.shape[2]}ê°œ")
        print(f"   - ëª¨ë¸ íƒ€ì…: {model_type}")
        print(f"   - ì €ì¥ëœ ëª¨ë¸: {model_name}")
        print("=" * 50)
        
        # íŠ¹ì§• ì¤‘ìš”ë„ ë¶„ì„ (ì˜µì…˜)
        if hasattr(detector, 'k_selector') and detector.k_selector:
            feature_scores = detector.k_selector.scores_
            selected_features = detector.k_selector.get_support(indices=True)
            print(f"\nğŸ” ì„ íƒëœ íŠ¹ì§• ì¸ë±ìŠ¤ (ìƒìœ„ 10ê°œ):")
            top_features = selected_features[np.argsort(feature_scores[selected_features])[-10:]]
            print(f"   {top_features}")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("ìƒì„¸ ì˜¤ë¥˜ ì •ë³´:")
        import traceback
        traceback.print_exc()
        
        # ì¼ë°˜ì ì¸ í•´ê²° ë°©ë²• ì œì‹œ
        print("\nğŸ’¡ ë¬¸ì œ í•´ê²° ë°©ë²•:")
        print("1. CSV íŒŒì¼ì— timestamp, label, feat_* ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸")
        print("2. ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ window_sizeë¥¼ ì¤„ì´ê±°ë‚˜ strideë¥¼ ëŠ˜ë ¤ë³´ì„¸ìš”")
        print("3. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸:")
        print("   pip install tensorflow pandas scikit-learn numpy matplotlib")
        print("4. CSV íŒŒì¼ì´ ì˜¬ë°”ë¥¸ í˜•ì‹ì¸ì§€ í™•ì¸:")
        print("   - ì²« ë²ˆì§¸ í–‰ì´ ì»¬ëŸ¼ëª…(í—¤ë”)ì¸ì§€ í™•ì¸")
        print("   - timestamp, label, feat_0, feat_1, ... ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸")

if __name__ == "__main__":
    main()