# model_builder.py
"""
CNN+LSTM í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ êµ¬ì¶•ê¸°
ê³ ì£¼íŒŒ CSI ë°ì´í„°ì— ìµœì í™”ëœ ì•„í‚¤í…ì²˜
"""

import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import (
    Input, Dense, LSTM, Conv1D, MaxPooling1D, Dropout, 
    BatchNormalization, GlobalAveragePooling1D, Concatenate,
    MultiHeadAttention, LayerNormalization
)
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
import logging
from config import CSIConfig

class CSIModelBuilder:
    """CSI ë‚™ìƒ ê°ì§€ ëª¨ë¸ êµ¬ì¶• í´ë˜ìŠ¤"""
    
    def __init__(self, input_shape=None, logger=None):
        """
        Args:
            input_shape: ì…ë ¥ í˜•íƒœ (window_size, feature_count)
            logger: ë¡œê±° ê°ì²´
        """
        self.logger = logger or logging.getLogger(__name__)
        
        # ì…ë ¥ í˜•íƒœ ì„¤ì •
        if input_shape is None:
            feature_count = CSIConfig.ACTIVE_FEATURE_COUNT
            self.input_shape = (CSIConfig.WINDOW_SIZE, feature_count)
        else:
            self.input_shape = input_shape
        
        self.model = None
        self.model_config = CSIConfig.get_model_config()
        
        self.logger.info(f"ğŸ—ï¸ ëª¨ë¸ ë¹Œë” ì´ˆê¸°í™”: ì…ë ¥ í˜•íƒœ {self.input_shape}")
    
    def build_basic_lstm(self):
        """ê¸°ë³¸ LSTM ëª¨ë¸"""
        self.logger.info("ğŸ“¦ ê¸°ë³¸ LSTM ëª¨ë¸ êµ¬ì¶•...")
        
        model = Sequential([
            LSTM(64, return_sequences=True, input_shape=self.input_shape, name='lstm_1'),
            Dropout(0.4),
            
            LSTM(32, return_sequences=False, name='lstm_2'),
            Dropout(0.4),
            
            Dense(16, activation='relu', name='dense_1'),
            BatchNormalization(),
            Dropout(0.3),
            
            Dense(1, activation='sigmoid', name='output')
        ])
        
        self.model = model
        self._compile_model()
        
        self.logger.info(f"âœ… ê¸°ë³¸ LSTM ëª¨ë¸ êµ¬ì¶• ì™„ë£Œ: {model.count_params():,} íŒŒë¼ë¯¸í„°")
        return model
    
    def build_cnn_lstm_hybrid(self):
        """CNN+LSTM í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ (ê¶Œì¥)"""
        self.logger.info("ğŸš€ CNN+LSTM í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ êµ¬ì¶•...")
        
        model = Sequential([
            # CNN ë¶€ë¶„ - ì§€ì—­ì  íŒ¨í„´ ì¶”ì¶œ
            Conv1D(filters=self.model_config['cnn_filters'][0], 
                   kernel_size=self.model_config['cnn_kernel_sizes'][0], 
                   activation='relu', 
                   input_shape=self.input_shape, 
                   name='conv1d_1'),
            BatchNormalization(),
            MaxPooling1D(pool_size=2),
            Dropout(self.model_config['dropout_rates'][0]),
            
            Conv1D(filters=self.model_config['cnn_filters'][1], 
                   kernel_size=self.model_config['cnn_kernel_sizes'][1], 
                   activation='relu', 
                   name='conv1d_2'),
            BatchNormalization(),
            Dropout(self.model_config['dropout_rates'][0]),
            
            # LSTM ë¶€ë¶„ - ì‹œê³„ì—´ íŒ¨í„´ í•™ìŠµ
            LSTM(self.model_config['lstm_units'][0], 
                 return_sequences=True, 
                 name='lstm_1'),
            Dropout(self.model_config['dropout_rates'][1]),
            
            LSTM(self.model_config['lstm_units'][1], 
                 return_sequences=False, 
                 name='lstm_2'),
            Dropout(self.model_config['dropout_rates'][1]),
            
            # ë¶„ë¥˜ ë¶€ë¶„
            Dense(self.model_config['dense_units'][0], 
                  activation='relu', 
                  name='dense_1'),
            BatchNormalization(),
            Dropout(self.model_config['dropout_rates'][2]),
            
            Dense(1, activation='sigmoid', name='output')
        ])
        
        self.model = model
        self._compile_model()
        
        self.logger.info(f"âœ… CNN+LSTM í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ êµ¬ì¶• ì™„ë£Œ: {model.count_params():,} íŒŒë¼ë¯¸í„°")
        return model
    
    def build_attention_model(self):
        """Attention ë©”ì»¤ë‹ˆì¦˜ í¬í•¨ ê³ ê¸‰ ëª¨ë¸"""
        self.logger.info("ğŸ§  Attention ëª¨ë¸ êµ¬ì¶•...")
        
        # í•¨ìˆ˜í˜• API ì‚¬ìš©
        inputs = Input(shape=self.input_shape, name='input')
        
        # CNN ë ˆì´ì–´
        x = Conv1D(64, kernel_size=5, activation='relu', name='conv1d_1')(inputs)
        x = BatchNormalization()(x)
        x = MaxPooling1D(pool_size=2)(x)
        x = Dropout(0.25)(x)
        
        x = Conv1D(32, kernel_size=3, activation='relu', name='conv1d_2')(x)
        x = BatchNormalization()(x)
        x = Dropout(0.25)(x)
        
        # LSTM ë ˆì´ì–´
        lstm_out = LSTM(64, return_sequences=True, name='lstm_1')(x)
        lstm_out = Dropout(0.4)(lstm_out)
        
        # Multi-Head Attention
        attention_out = MultiHeadAttention(
            num_heads=4, 
            key_dim=16, 
            name='multi_head_attention'
        )(lstm_out, lstm_out)
        
        # Residual connection + Layer Normalization
        attention_out = LayerNormalization()(attention_out + lstm_out)
        
        # Global Average Pooling
        pooled = GlobalAveragePooling1D()(attention_out)
        
        # ë¶„ë¥˜ ë ˆì´ì–´
        dense = Dense(16, activation='relu', name='dense_1')(pooled)
        dense = BatchNormalization()(dense)
        dense = Dropout(0.3)(dense)
        
        outputs = Dense(1, activation='sigmoid', name='output')(dense)
        
        model = Model(inputs=inputs, outputs=outputs, name='CSI_Attention_Model')
        
        self.model = model
        self._compile_model()
        
        self.logger.info(f"âœ… Attention ëª¨ë¸ êµ¬ì¶• ì™„ë£Œ: {model.count_params():,} íŒŒë¼ë¯¸í„°")
        return model
    
    def build_multi_scale_model(self):
        """ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ íŠ¹ì„± ì¶”ì¶œ ëª¨ë¸"""
        self.logger.info("ğŸ”¬ ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ëª¨ë¸ êµ¬ì¶•...")
        
        inputs = Input(shape=self.input_shape, name='input')
        
        # ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ CNN ë¸Œëœì¹˜
        # ë¸Œëœì¹˜ 1: ì§§ì€ íŒ¨í„´ (kernel_size=3)
        conv1_1 = Conv1D(32, kernel_size=3, activation='relu', padding='same')(inputs)
        conv1_1 = BatchNormalization()(conv1_1)
        conv1_1 = MaxPooling1D(pool_size=2)(conv1_1)
        
        # ë¸Œëœì¹˜ 2: ì¤‘ê°„ íŒ¨í„´ (kernel_size=5)
        conv1_2 = Conv1D(32, kernel_size=5, activation='relu', padding='same')(inputs)
        conv1_2 = BatchNormalization()(conv1_2)
        conv1_2 = MaxPooling1D(pool_size=2)(conv1_2)
        
        # ë¸Œëœì¹˜ 3: ê¸´ íŒ¨í„´ (kernel_size=7)
        conv1_3 = Conv1D(32, kernel_size=7, activation='relu', padding='same')(inputs)
        conv1_3 = BatchNormalization()(conv1_3)
        conv1_3 = MaxPooling1D(pool_size=2)(conv1_3)
        
        # ë¸Œëœì¹˜ ê²°í•©
        merged = Concatenate(axis=-1)([conv1_1, conv1_2, conv1_3])
        merged = Dropout(0.25)(merged)
        
        # ì¶”ê°€ CNN ë ˆì´ì–´
        x = Conv1D(64, kernel_size=3, activation='relu')(merged)
        x = BatchNormalization()(x)
        x = Dropout(0.25)(x)
        
        # LSTM ë ˆì´ì–´
        x = LSTM(64, return_sequences=True)(x)
        x = Dropout(0.4)(x)
        
        x = LSTM(32, return_sequences=False)(x)
        x = Dropout(0.4)(x)
        
        # ë¶„ë¥˜ ë ˆì´ì–´
        x = Dense(16, activation='relu')(x)
        x = BatchNormalization()(x)
        x = Dropout(0.3)(x)
        
        outputs = Dense(1, activation='sigmoid', name='output')(x)
        
        model = Model(inputs=inputs, outputs=outputs, name='CSI_MultiScale_Model')
        
        self.model = model
        self._compile_model()
        
        self.logger.info(f"âœ… ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ëª¨ë¸ êµ¬ì¶• ì™„ë£Œ: {model.count_params():,} íŒŒë¼ë¯¸í„°")
        return model
    
    def build_lightweight_model(self):
        """ê²½ëŸ‰í™” ëª¨ë¸ (ì‹¤ì‹œê°„ ì²˜ë¦¬ìš©)"""
        self.logger.info("âš¡ ê²½ëŸ‰í™” ëª¨ë¸ êµ¬ì¶•...")
        
        model = Sequential([
            # ê²½ëŸ‰ CNN
            Conv1D(16, kernel_size=5, activation='relu', input_shape=self.input_shape),
            BatchNormalization(),
            MaxPooling1D(pool_size=4),  # ë” í° í’€ë§
            Dropout(0.2),
            
            Conv1D(8, kernel_size=3, activation='relu'),
            BatchNormalization(),
            Dropout(0.2),
            
            # ê²½ëŸ‰ LSTM
            LSTM(32, return_sequences=False),
            Dropout(0.3),
            
            # ê°„ë‹¨í•œ ë¶„ë¥˜ê¸°
            Dense(8, activation='relu'),
            Dropout(0.2),
            Dense(1, activation='sigmoid')
        ])
        
        self.model = model
        self._compile_model()
        
        self.logger.info(f"âœ… ê²½ëŸ‰í™” ëª¨ë¸ êµ¬ì¶• ì™„ë£Œ: {model.count_params():,} íŒŒë¼ë¯¸í„°")
        return model
    
    def _compile_model(self):
        """ëª¨ë¸ ì»´íŒŒì¼"""
        optimizer = Adam(learning_rate=self.model_config['learning_rate'])
        
        try:
            # TensorFlow 2.x í˜¸í™˜ ë©”íŠ¸ë¦­
            self.model.compile(
                optimizer=optimizer,
                loss='binary_crossentropy',
                metrics=[
                    'accuracy',
                    tf.keras.metrics.Precision(name='precision'),
                    tf.keras.metrics.Recall(name='recall')
                ]
            )
        except Exception as e:
            self.logger.warning(f"ê³ ê¸‰ ë©”íŠ¸ë¦­ ì„¤ì • ì‹¤íŒ¨, ê¸°ë³¸ ì„¤ì • ì‚¬ìš©: {e}")
            # ë°±ì—…: ê¸°ë³¸ ë©”íŠ¸ë¦­ë§Œ ì‚¬ìš©
            self.model.compile(
                optimizer=optimizer,
                loss='binary_crossentropy',
                metrics=['accuracy']
            )
    
    def get_model_summary(self):
        """ëª¨ë¸ ìš”ì•½ ì •ë³´"""
        if self.model is None:
            return "ëª¨ë¸ì´ êµ¬ì¶•ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        summary_lines = []
        self.model.summary(print_fn=lambda x: summary_lines.append(x))
        return '\n'.join(summary_lines)
    
    def visualize_model(self, filename='model_architecture.png'):
        """ëª¨ë¸ ì•„í‚¤í…ì²˜ ì‹œê°í™”"""
        if self.model is None:
            self.logger.error("ëª¨ë¸ì´ êµ¬ì¶•ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
            return None
        
        try:
            tf.keras.utils.plot_model(
                self.model, 
                to_file=filename,
                show_shapes=True,
                show_layer_names=True,
                rankdir='TB',
                expand_nested=True,
                dpi=150
            )
            self.logger.info(f"ğŸ“Š ëª¨ë¸ ì•„í‚¤í…ì²˜ ì €ì¥: {filename}")
            return filename
        except Exception as e:
            self.logger.warning(f"ëª¨ë¸ ì‹œê°í™” ì‹¤íŒ¨: {e}")
            return None
    
    def create_callbacks(self, model_save_path, monitor='val_loss'):
        """í›ˆë ¨ ì½œë°± ìƒì„±"""
        callbacks = [
            EarlyStopping(
                monitor=monitor,
                patience=CSIConfig.PATIENCE,
                restore_best_weights=True,
                verbose=1,
                mode='min'
            ),
            ReduceLROnPlateau(
                monitor=monitor,
                factor=0.5,
                patience=CSIConfig.PATIENCE // 2,
                min_lr=1e-7,
                verbose=1,
                mode='min'
            ),
            ModelCheckpoint(
                filepath=model_save_path,
                monitor=monitor,
                save_best_only=True,
                verbose=1,
                mode='min'
            )
        ]
        
        return callbacks
    
    def build_model(self, model_type='cnn_lstm_hybrid'):
        """ì§€ì •ëœ íƒ€ì…ì˜ ëª¨ë¸ êµ¬ì¶•"""
        model_builders = {
            'basic_lstm': self.build_basic_lstm,
            'cnn_lstm_hybrid': self.build_cnn_lstm_hybrid,
            'attention': self.build_attention_model,
            'multi_scale': self.build_multi_scale_model,
            'lightweight': self.build_lightweight_model
        }
        
        if model_type not in model_builders:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ íƒ€ì…: {model_type}")
        
        self.logger.info(f"ğŸ—ï¸ ëª¨ë¸ êµ¬ì¶• ì‹œì‘: {model_type}")
        model = model_builders[model_type]()
        
        # ëª¨ë¸ ìš”ì•½ ì¶œë ¥
        self.logger.info(f"ğŸ“‹ ëª¨ë¸ ìš”ì•½:\n{self.get_model_summary()}")
        
        return model
    
    def compare_models(self):
        """ë‹¤ì–‘í•œ ëª¨ë¸ë“¤ì˜ íŒŒë¼ë¯¸í„° ìˆ˜ ë¹„êµ"""
        models_info = {}
        
        for model_type in ['basic_lstm', 'cnn_lstm_hybrid', 'attention', 'multi_scale', 'lightweight']:
            try:
                # ì„ì‹œë¡œ ëª¨ë¸ êµ¬ì¶•
                temp_builder = CSIModelBuilder(self.input_shape)
                temp_model = temp_builder.build_model(model_type)
                
                models_info[model_type] = {
                    'params': temp_model.count_params(),
                    'trainable_params': temp_model.count_params(),
                    'layers': len(temp_model.layers)
                }
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                del temp_model, temp_builder
                
            except Exception as e:
                models_info[model_type] = {'error': str(e)}
        
        return models_info
    
    def print_model_comparison(self):
        """ëª¨ë¸ ë¹„êµ ì •ë³´ ì¶œë ¥"""
        print("ğŸ” ëª¨ë¸ ì•„í‚¤í…ì²˜ ë¹„êµ")
        print("=" * 60)
        
        models_info = self.compare_models()
        
        for model_type, info in models_info.items():
            print(f"\nğŸ“¦ {model_type.upper().replace('_', ' ')}:")
            if 'error' in info:
                print(f"   âŒ êµ¬ì¶• ì‹¤íŒ¨: {info['error']}")
            else:
                print(f"   íŒŒë¼ë¯¸í„° ìˆ˜: {info['params']:,}ê°œ")
                print(f"   ë ˆì´ì–´ ìˆ˜: {info['layers']}ê°œ")
                
                # ë³µì¡ë„ í‰ê°€
                if info['params'] < 50000:
                    complexity = "ê°€ë²¼ì›€ âš¡"
                elif info['params'] < 200000:
                    complexity = "ë³´í†µ âš–ï¸"
                else:
                    complexity = "ë¬´ê±°ì›€ ğŸ‹ï¸"
                
                print(f"   ë³µì¡ë„: {complexity}")

# ëª¨ë¸ ì¶”ì²œ í•¨ìˆ˜
def recommend_model(use_case='general'):
    """ì‚¬ìš© ëª©ì ì— ë”°ë¥¸ ëª¨ë¸ ì¶”ì²œ"""
    recommendations = {
        'general': 'cnn_lstm_hybrid',
        'high_accuracy': 'attention',
        'real_time': 'lightweight',
        'research': 'multi_scale',
        'simple': 'basic_lstm'
    }
    
    return recommendations.get(use_case, 'cnn_lstm_hybrid')

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("ğŸ§ª CSI ëª¨ë¸ ë¹Œë” í…ŒìŠ¤íŠ¸")
    print("=" * 40)
    
    # ëª¨ë¸ ë¹Œë” ìƒì„±
    builder = CSIModelBuilder()
    
    # ëª¨ë¸ ë¹„êµ
    builder.print_model_comparison()
    
    # ì¶”ì²œ ëª¨ë¸ êµ¬ì¶•
    print(f"\nğŸ¯ ì¶”ì²œ ëª¨ë¸ êµ¬ì¶•...")
    recommended_type = recommend_model('general')
    model = builder.build_model(recommended_type)
    
    print(f"âœ… {recommended_type} ëª¨ë¸ êµ¬ì¶• ì™„ë£Œ!")
    print(f"   íŒŒë¼ë¯¸í„°: {model.count_params():,}ê°œ")
    
    # ì•„í‚¤í…ì²˜ ì‹œê°í™” (ì„ íƒì )
    try:
        builder.visualize_model('test_model.png')
    except:
        print("   âš ï¸ ëª¨ë¸ ì‹œê°í™” ìŠ¤í‚µ (graphviz ë¯¸ì„¤ì¹˜)")