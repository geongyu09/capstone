# model_tester.py
import pandas as pd
import numpy as np
import os
import glob
import pickle
import json
from datetime import datetime
from tensorflow.keras.models import load_model
import matplotlib.pyplot as plt

class CSIModelTester:
    """í•™ìŠµëœ CSI ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.model = None
        self.scaler = None
        self.feature_selector = None
        self.metadata = None
        
        # ëª¨ë¸ ì •ë³´
        self.window_size = None
        self.stride = None
        self.overlap_threshold = None
    
    def find_latest_model(self, pattern="*model*.keras"):
        """ê°€ì¥ ìµœê·¼ í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ ì°¾ê¸°"""
        print("ğŸ” í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ ì°¾ëŠ” ì¤‘...")
        
        # .keras íŒŒì¼ë“¤ ì°¾ê¸°
        keras_files = glob.glob(pattern)
        
        # .h5 íŒŒì¼ë“¤ë„ ì°¾ê¸°
        h5_files = glob.glob(pattern.replace('.keras', '.h5'))
        
        all_models = keras_files + h5_files
        
        if not all_models:
            print("âŒ í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            print("ğŸ’¡ ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ë¨¼ì € í•™ìŠµì„ ì§„í–‰í•˜ì„¸ìš”:")
            print("   python v2/multi_file_trainer.py")
            return None
        
        # ê°€ì¥ ìµœê·¼ íŒŒì¼ ì„ íƒ
        latest_model = max(all_models, key=os.path.getctime)
        
        print(f"âœ… ìµœì‹  ëª¨ë¸ ë°œê²¬: {latest_model}")
        
        # íŒŒì¼ ì •ë³´ ì¶œë ¥
        file_size = os.path.getsize(latest_model) / 1024  # KB
        create_time = datetime.fromtimestamp(os.path.getctime(latest_model))
        print(f"   ğŸ“„ í¬ê¸°: {file_size:.1f} KB")
        print(f"   ğŸ• ìƒì„± ì‹œê°„: {create_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        return latest_model
    
    def load_model_and_preprocessors(self, model_path):
        """ëª¨ë¸ê³¼ ì „ì²˜ë¦¬ê¸°ë“¤ ë¡œë“œ"""
        print(f"ğŸ“¥ ëª¨ë¸ ë¡œë”©: {os.path.basename(model_path)}")
        
        try:
            # 1. ëª¨ë¸ ë¡œë“œ
            self.model = load_model(model_path)
            print(f"   âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            print(f"   ğŸ“Š ëª¨ë¸ êµ¬ì¡°: {self.model.input_shape} â†’ {self.model.output_shape}")
            
            # 2. ì „ì²˜ë¦¬ê¸° ë¡œë“œ
            base_path = model_path.replace('.keras', '').replace('.h5', '')
            
            # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
            scaler_path = base_path + '_scaler.pkl'
            if os.path.exists(scaler_path):
                with open(scaler_path, 'rb') as f:
                    self.scaler = pickle.load(f)
                print(f"   âœ… ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ")
            else:
                print(f"   âš ï¸ ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ ì—†ìŒ: {scaler_path}")
            
            # íŠ¹ì§• ì„ íƒê¸° ë¡œë“œ
            selector_path = base_path + '_selector.pkl'
            if os.path.exists(selector_path):
                with open(selector_path, 'rb') as f:
                    self.feature_selector = pickle.load(f)
                print(f"   âœ… íŠ¹ì§• ì„ íƒê¸° ë¡œë“œ ì™„ë£Œ")
            else:
                print(f"   âš ï¸ íŠ¹ì§• ì„ íƒê¸° íŒŒì¼ ì—†ìŒ: {selector_path}")
            
            # ë©”íƒ€ë°ì´í„° ë¡œë“œ
            metadata_path = base_path + '_metadata.json'
            if os.path.exists(metadata_path):
                with open(metadata_path, 'r', encoding='utf-8') as f:
                    self.metadata = json.load(f)
                print(f"   âœ… ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
                
                # ë©”íƒ€ë°ì´í„°ì—ì„œ ì„¤ì •ê°’ ì¶”ì¶œ
                self.window_size = self.metadata.get('window_size', 50)
                self.stride = self.metadata.get('stride', 5)
                self.overlap_threshold = self.metadata.get('overlap_threshold', 0.3)
                
                print(f"   ğŸ“‹ ëª¨ë¸ ì„¤ì •: ìœˆë„ìš°={self.window_size}, ìŠ¤íŠ¸ë¼ì´ë“œ={self.stride}")
            else:
                print(f"   âš ï¸ ë©”íƒ€ë°ì´í„° íŒŒì¼ ì—†ìŒ: {metadata_path}")
                # ê¸°ë³¸ê°’ ì‚¬ìš©
                self.window_size = 50
                self.stride = 5
                self.overlap_threshold = 0.3
            
            return True
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def preprocess_data(self, X):
        """ë°ì´í„° ì „ì²˜ë¦¬ (í•™ìŠµ ì‹œì™€ ë™ì¼í•˜ê²Œ)"""
        print("ğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬...")
        
        # 1. íŠ¹ì§• ì„ íƒ ì ìš©
        if self.feature_selector:
            print("   ğŸ“Š íŠ¹ì§• ì„ íƒ ì ìš©...")
            
            if 'variance_selector' in self.feature_selector:
                X_var = self.feature_selector['variance_selector'].transform(X)
                
                if self.feature_selector.get('k_selector'):
                    X_selected = self.feature_selector['k_selector'].transform(X_var)
                else:
                    X_selected = X_var
            else:
                # ê°„ë‹¨í•œ ì„ íƒ (ê¸°ë³¸ê°’)
                X_selected = X[:, 10:246] if X.shape[1] > 246 else X
        else:
            print("   âš ï¸ íŠ¹ì§• ì„ íƒê¸° ì—†ìŒ, ì›ë³¸ ë°ì´í„° ì‚¬ìš©")
            X_selected = X
        
        print(f"      íŠ¹ì§• ì„ íƒ í›„: {X.shape[1]} â†’ {X_selected.shape[1]}ê°œ")
        
        # 2. ì •ê·œí™” ì ìš©
        if self.scaler:
            print("   ğŸ“ ì •ê·œí™” ì ìš©...")
            X_normalized = self.scaler.transform(X_selected)
        else:
            print("   âš ï¸ ìŠ¤ì¼€ì¼ëŸ¬ ì—†ìŒ, ì •ê·œí™” ê±´ë„ˆë›°ê¸°")
            X_normalized = X_selected
        
        return X_normalized
    
    def create_sequences(self, X, y=None):
        """ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ìƒì„±"""
        print("â° ì‹œí€€ìŠ¤ ìƒì„±...")
        
        sequences = []
        labels = []
        
        for i in range(0, len(X) - self.window_size + 1, self.stride):
            window_X = X[i:i + self.window_size]
            sequences.append(window_X)
            
            if y is not None:
                window_y = y[i:i + self.window_size]
                # ë¼ë²¨ë§ (í•™ìŠµ ì‹œì™€ ë™ì¼)
                fall_ratio = np.sum(window_y == 1) / len(window_y)
                sequence_label = 1 if fall_ratio >= self.overlap_threshold else 0
                labels.append(sequence_label)
        
        X_seq = np.array(sequences)
        y_seq = np.array(labels) if y is not None else None
        
        print(f"   âœ… ìƒì„±ëœ ì‹œí€€ìŠ¤: {X_seq.shape[0]}ê°œ")
        print(f"   ğŸ“Š ì‹œí€€ìŠ¤ í˜•íƒœ: {X_seq.shape}")
        
        return X_seq, y_seq
    
    def test_on_csv(self, csv_path):
        """CSV íŒŒì¼ì—ì„œ ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
        print(f"\nğŸ“„ CSV íŒŒì¼ í…ŒìŠ¤íŠ¸: {os.path.basename(csv_path)}")
        
        try:
            # 1. CSV ë¡œë“œ
            df = pd.read_csv(csv_path)
            print(f"   ğŸ“Š íŒŒì¼ í¬ê¸°: {df.shape}")
            
            # 2. íŠ¹ì§• ì¶”ì¶œ
            feature_cols = [col for col in df.columns if col.startswith('feat_')]
            X = df[feature_cols].values
            y = df['label'].values if 'label' in df.columns else None
            
            print(f"   ğŸ“ˆ íŠ¹ì§• ìˆ˜: {len(feature_cols)}ê°œ")
            if y is not None:
                unique, counts = np.unique(y, return_counts=True)
                print(f"   ğŸ·ï¸ ë¼ë²¨ ë¶„í¬: {dict(zip(unique, counts))}")
            
            # 3. ì „ì²˜ë¦¬
            X_processed = self.preprocess_data(X)
            
            # 4. ì‹œí€€ìŠ¤ ìƒì„±
            X_seq, y_seq = self.create_sequences(X_processed, y)
            
            # 5. ì˜ˆì¸¡ ìˆ˜í–‰
            print("ğŸ”® ì˜ˆì¸¡ ìˆ˜í–‰...")
            predictions = self.model.predict(X_seq, verbose=0)
            pred_probabilities = predictions.flatten()
            pred_labels = (pred_probabilities > 0.5).astype(int)
            
            print(f"   âœ… ì˜ˆì¸¡ ì™„ë£Œ: {len(predictions)}ê°œ ì‹œí€€ìŠ¤")
            
            # 6. ê²°ê³¼ ë¶„ì„
            self.analyze_predictions(pred_probabilities, pred_labels, y_seq)
            
            # 7. ì‹œê°í™”
            self.visualize_results(pred_probabilities, pred_labels, y_seq)
            
            return pred_probabilities, pred_labels, y_seq
            
        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return None, None, None
    
    def analyze_predictions(self, pred_probs, pred_labels, true_labels=None):
        """ì˜ˆì¸¡ ê²°ê³¼ ë¶„ì„"""
        print("\nğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ë¶„ì„:")
        
        # ê¸°ë³¸ í†µê³„
        print(f"   ğŸ”® ì˜ˆì¸¡ í†µê³„:")
        print(f"      í‰ê·  í™•ë¥ : {np.mean(pred_probs):.3f}")
        print(f"      ìµœëŒ€ í™•ë¥ : {np.max(pred_probs):.3f}")
        print(f"      ìµœì†Œ í™•ë¥ : {np.min(pred_probs):.3f}")
        
        # ì˜ˆì¸¡ ë¶„í¬
        unique_preds, pred_counts = np.unique(pred_labels, return_counts=True)
        print(f"   ğŸ“ˆ ì˜ˆì¸¡ ë¶„í¬:")
        for label, count in zip(unique_preds, pred_counts):
            label_name = "ë‚™ìƒ" if label == 1 else "ì •ìƒ"
            percentage = (count / len(pred_labels)) * 100
            print(f"      {label_name}: {count}ê°œ ({percentage:.1f}%)")
        
        # ì‹¤ì œ ë¼ë²¨ì´ ìˆìœ¼ë©´ ì„±ëŠ¥ í‰ê°€
        if true_labels is not None:
            from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix
            
            print(f"   ğŸ¯ ì„±ëŠ¥ í‰ê°€:")
            
            accuracy = accuracy_score(true_labels, pred_labels)
            print(f"      ì •í™•ë„: {accuracy:.3f} ({accuracy*100:.1f}%)")
            
            if len(np.unique(true_labels)) > 1:  # ë‘ í´ë˜ìŠ¤ ëª¨ë‘ ìˆëŠ” ê²½ìš°
                precision = precision_score(true_labels, pred_labels, zero_division=0)
                recall = recall_score(true_labels, pred_labels, zero_division=0)
                f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
                
                print(f"      ì •ë°€ë„: {precision:.3f} ({precision*100:.1f}%)")
                print(f"      ì¬í˜„ìœ¨: {recall:.3f} ({recall*100:.1f}%)")
                print(f"      F1-ì ìˆ˜: {f1:.3f}")
                
                # í˜¼ë™ í–‰ë ¬
                cm = confusion_matrix(true_labels, pred_labels)
                print(f"   ğŸ“‹ í˜¼ë™ í–‰ë ¬:")
                print(f"      ì‹¤ì œ\\ì˜ˆì¸¡  ì •ìƒ  ë‚™ìƒ")
                print(f"      ì •ìƒ     {cm[0,0]:4d}  {cm[0,1]:4d}")
                print(f"      ë‚™ìƒ     {cm[1,0]:4d}  {cm[1,1]:4d}")
                
                # ë‚™ìƒ ê°ì§€ ê´€ì 
                if cm[1,1] + cm[1,0] > 0:  # ì‹¤ì œ ë‚™ìƒì´ ìˆëŠ” ê²½ìš°
                    miss_rate = cm[1,0] / (cm[1,1] + cm[1,0])
                    false_alarm_rate = cm[0,1] / (cm[0,0] + cm[0,1]) if (cm[0,0] + cm[0,1]) > 0 else 0
                    
                    print(f"   ğŸ¯ ë‚™ìƒ ê°ì§€ ê´€ì :")
                    print(f"      ë†“ì¹œ ë‚™ìƒ: {miss_rate*100:.1f}%")
                    print(f"      ê±°ì§“ ì•ŒëŒ: {false_alarm_rate*100:.1f}%")
    
    def visualize_results(self, pred_probs, pred_labels, true_labels=None):
        """ê²°ê³¼ ì‹œê°í™”"""
        print("\nğŸ“Š ê²°ê³¼ ì‹œê°í™” ì¤‘...")
        
        try:
            fig, axes = plt.subplots(2, 2, figsize=(15, 10))
            
            # 1. ì˜ˆì¸¡ í™•ë¥  ë¶„í¬
            axes[0,0].hist(pred_probs, bins=30, alpha=0.7, color='blue', edgecolor='black')
            axes[0,0].axvline(x=0.5, color='red', linestyle='--', label='ì„ê³„ê°’ (0.5)')
            axes[0,0].set_title('ì˜ˆì¸¡ í™•ë¥  ë¶„í¬')
            axes[0,0].set_xlabel('ë‚™ìƒ í™•ë¥ ')
            axes[0,0].set_ylabel('ë¹ˆë„')
            axes[0,0].legend()
            axes[0,0].grid(True, alpha=0.3)
            
            # 2. ì‹œê°„ì— ë”°ë¥¸ ì˜ˆì¸¡ í™•ë¥ 
            axes[0,1].plot(pred_probs, linewidth=1.5, color='blue', label='ì˜ˆì¸¡ í™•ë¥ ')
            axes[0,1].axhline(y=0.5, color='red', linestyle='--', alpha=0.7, label='ì„ê³„ê°’')
            
            if true_labels is not None:
                # ì‹¤ì œ ë‚™ìƒ êµ¬ê°„ í‘œì‹œ
                fall_indices = np.where(true_labels == 1)[0]
                if len(fall_indices) > 0:
                    axes[0,1].scatter(fall_indices, pred_probs[fall_indices], 
                                    color='red', s=20, alpha=0.7, label='ì‹¤ì œ ë‚™ìƒ')
            
            axes[0,1].set_title('ì‹œê°„ì— ë”°ë¥¸ ì˜ˆì¸¡ í™•ë¥ ')
            axes[0,1].set_xlabel('ì‹œí€€ìŠ¤ ë²ˆí˜¸')
            axes[0,1].set_ylabel('ë‚™ìƒ í™•ë¥ ')
            axes[0,1].legend()
            axes[0,1].grid(True, alpha=0.3)
            
            # 3. ì˜ˆì¸¡ ë¼ë²¨ ë¶„í¬ (íŒŒì´ ì°¨íŠ¸)
            unique_preds, pred_counts = np.unique(pred_labels, return_counts=True)
            labels = ['ì •ìƒ' if x == 0 else 'ë‚™ìƒ' for x in unique_preds]
            colors = ['lightblue' if x == 0 else 'lightcoral' for x in unique_preds]
            
            axes[1,0].pie(pred_counts, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)
            axes[1,0].set_title('ì˜ˆì¸¡ ë¼ë²¨ ë¶„í¬')
            
            # 4. ì‹¤ì œ vs ì˜ˆì¸¡ ë¹„êµ (ë¼ë²¨ì´ ìˆëŠ” ê²½ìš°)
            if true_labels is not None:
                # ì‹¤ì œ ë¼ë²¨ë³„ ì˜ˆì¸¡ í™•ë¥  ë¶„í¬
                normal_probs = pred_probs[true_labels == 0]
                fall_probs = pred_probs[true_labels == 1]
                
                axes[1,1].hist(normal_probs, bins=20, alpha=0.7, label='ì‹¤ì œ ì •ìƒ', color='blue', density=True)
                axes[1,1].hist(fall_probs, bins=20, alpha=0.7, label='ì‹¤ì œ ë‚™ìƒ', color='red', density=True)
                axes[1,1].axvline(x=0.5, color='black', linestyle='--', alpha=0.7, label='ì„ê³„ê°’')
                axes[1,1].set_title('ì‹¤ì œ ë¼ë²¨ë³„ ì˜ˆì¸¡ í™•ë¥ ')
                axes[1,1].set_xlabel('ì˜ˆì¸¡ í™•ë¥ ')
                axes[1,1].set_ylabel('ë°€ë„')
                axes[1,1].legend()
                axes[1,1].grid(True, alpha=0.3)
            else:
                axes[1,1].text(0.5, 0.5, 'ì‹¤ì œ ë¼ë²¨ ì—†ìŒ', ha='center', va='center', 
                              transform=axes[1,1].transAxes, fontsize=14)
                axes[1,1].set_title('ì‹¤ì œ ë¼ë²¨ ì—†ìŒ')
            
            plt.tight_layout()
            
            # ì´ë¯¸ì§€ ì €ì¥
            timestamp = datetime.now().strftime('%H%M%S')
            filename = f'model_test_results_{timestamp}.png'
            plt.savefig(filename, dpi=300, bbox_inches='tight')
            print(f"   ğŸ’¾ ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥: {filename}")
            
            plt.show()
            
        except Exception as e:
            print(f"âŒ ì‹œê°í™” ì‹¤íŒ¨: {e}")
    
    def quick_test(self, csv_path=None):
        """ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸš€ CSI ëª¨ë¸ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸")
        print("=" * 50)
        
        # 1. ëª¨ë¸ ì°¾ê¸° ë° ë¡œë“œ
        model_path = self.find_latest_model()
        if not model_path:
            return False
        
        if not self.load_model_and_preprocessors(model_path):
            return False
        
        # 2. í…ŒìŠ¤íŠ¸ íŒŒì¼ ì°¾ê¸° (ë‹¤ì–‘í•œ ê²½ë¡œ ì§€ì›)
        if csv_path is None:
            test_files = [
                # í˜„ì¬ ë””ë ‰í† ë¦¬
                '32_labeled.csv', 
                'case32.csv', 
                'test.csv',
                # ìƒìœ„ ë””ë ‰í† ë¦¬
                '../32_labeled.csv',
                '../case32.csv',
                # csi_data í•˜ìœ„ ë””ë ‰í† ë¦¬ë“¤
                '../csi_data/case3/32_labeled.csv',
                '../csi_data/case2/5.csv', 
                '../csi_data/case1/40.csv',
                '../csi_data/case1/32_labeled.csv',
                '../csi_data/case2/32_labeled.csv',
                '../csi_data/case3/5.csv',
                # í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ í•˜ìœ„ í´ë”ë“¤
                './case1/32_labeled.csv',
                './case2/5.csv',
                './case3/40.csv'
            ]
            
            csv_path = None
            print("ğŸ” í…ŒìŠ¤íŠ¸ íŒŒì¼ ì°¾ëŠ” ì¤‘...")
            
            for test_file in test_files:
                if os.path.exists(test_file):
                    csv_path = test_file
                    print(f"   âœ… ë°œê²¬: {test_file}")
                    break
                else:
                    print(f"   âŒ ì—†ìŒ: {test_file}")
            
            if csv_path is None:
                print("\nğŸ” ì¶”ê°€ ê²€ìƒ‰ ì¤‘...")
                # ì¶”ê°€ ê²€ìƒ‰: í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  CSV
                current_csv = glob.glob("*.csv")
                print(f"   í˜„ì¬ ë””ë ‰í† ë¦¬ CSV: {current_csv}")
                
                # ì¶”ê°€ ê²€ìƒ‰: ìƒìœ„ ë””ë ‰í† ë¦¬ CSV
                parent_csv = glob.glob("../*.csv")
                print(f"   ìƒìœ„ ë””ë ‰í† ë¦¬ CSV: {parent_csv}")
                
                # ì¶”ê°€ ê²€ìƒ‰: csi_data í•˜ìœ„ì˜ ëª¨ë“  CSV
                csi_data_csv = glob.glob("../csi_data/**/*.csv", recursive=True)
                print(f"   csi_data í•˜ìœ„ CSV: {len(csi_data_csv)}ê°œ")
                
                if csi_data_csv:
                    print(f"   csi_data CSV ì˜ˆì‹œ:")
                    for i, csv_file in enumerate(csi_data_csv[:5]):
                        file_size = os.path.getsize(csv_file) / 1024
                        print(f"      {i+1}. {csv_file} ({file_size:.1f} KB)")
                    if len(csi_data_csv) > 5:
                        print(f"      ... ì™¸ {len(csi_data_csv)-5}ê°œ")
                
                # ê°€ì¥ í° CSV íŒŒì¼ ì„ íƒ
                all_csv = current_csv + parent_csv + csi_data_csv
                if all_csv:
                    csv_sizes = [(f, os.path.getsize(f)) for f in all_csv]
                    csv_path = max(csv_sizes, key=lambda x: x[1])[0]
                    print(f"   ğŸ¯ ê°€ì¥ í° íŒŒì¼ ì„ íƒ: {csv_path}")
                else:
                    print("âŒ í…ŒìŠ¤íŠ¸í•  CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
                    print("\nğŸ’¡ í•´ê²° ë°©ë²•:")
                    print("   1. CSV íŒŒì¼ì„ í˜„ì¬ ë””ë ‰í† ë¦¬ë¡œ ë³µì‚¬")
                    print("   2. ì§ì ‘ ê²½ë¡œ ì§€ì •:")
                    print("      tester.quick_test('../csi_data/case3/32_labeled.csv')")
                    print("   3. íŒŒì¼ ê²½ë¡œ í™•ì¸:")
                    print("      ls ../csi_data/case*/*.csv")
                    return False
        
        # íŒŒì¼ ì¡´ì¬ ì¬í™•ì¸
        if not os.path.exists(csv_path):
            print(f"âŒ ì„ íƒëœ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {csv_path}")
            return False
        
        # 3. í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        print(f"\nğŸ“„ í…ŒìŠ¤íŠ¸ íŒŒì¼: {csv_path}")
        file_size = os.path.getsize(csv_path) / 1024
        print(f"   íŒŒì¼ í¬ê¸°: {file_size:.1f} KB")
        
        pred_probs, pred_labels, true_labels = self.test_on_csv(csv_path)
        
        if pred_probs is not None:
            print(f"\nâœ… ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
            print(f"ğŸ“„ í…ŒìŠ¤íŠ¸ íŒŒì¼: {os.path.basename(csv_path)}")
            print(f"ğŸ”® ì˜ˆì¸¡ ìˆ˜í–‰: {len(pred_probs)}ê°œ ì‹œí€€ìŠ¤")
            
            # ê°„ë‹¨í•œ ìš”ì•½
            fall_predictions = np.sum(pred_labels == 1)
            max_prob = np.max(pred_probs)
            
            print(f"\nğŸ“‹ í…ŒìŠ¤íŠ¸ ìš”ì•½:")
            print(f"   ë‚™ìƒ ì˜ˆì¸¡: {fall_predictions}ê°œ ì‹œí€€ìŠ¤")
            print(f"   ìµœëŒ€ í™•ë¥ : {max_prob:.3f}")
            
            if max_prob > 0.8:
                print(f"   ğŸš¨ ë†’ì€ í™•ë¥ ì˜ ë‚™ìƒ ê°ì§€ë¨!")
            elif max_prob > 0.5:
                print(f"   âš ï¸ ë‚™ìƒ ê°€ëŠ¥ì„± ìˆìŒ")
            else:
                print(f"   âœ… ì •ìƒ ìƒíƒœë¡œ íŒë‹¨ë¨")
            
            return True
        
        return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    tester = CSIModelTester()
    
    print("ğŸ§ª CSI ëª¨ë¸ í…ŒìŠ¤í„°")
    print("=" * 30)
    print("1. ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (q)")
    print("2. íŠ¹ì • íŒŒì¼ í…ŒìŠ¤íŠ¸ (f)")
    print("3. ëª¨ë¸ ì •ë³´ë§Œ í™•ì¸ (i)")
    print("4. ì¶”ì²œ íŒŒì¼ë¡œ í…ŒìŠ¤íŠ¸ (r)")
    
    choice = input("\nì„ íƒí•˜ì„¸ìš” (q/f/i/r): ").strip().lower()
    
    if choice == 'q':
        # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
        tester.quick_test()
        
    elif choice == 'f':
        # íŠ¹ì • íŒŒì¼ í…ŒìŠ¤íŠ¸
        csv_file = input("CSV íŒŒì¼ ê²½ë¡œ: ").strip()
        if os.path.exists(csv_file):
            tester.quick_test(csv_file)
        else:
            print(f"âŒ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {csv_file}")
    
    elif choice == 'i':
        # ëª¨ë¸ ì •ë³´ë§Œ í™•ì¸
        model_path = tester.find_latest_model()
        if model_path:
            tester.load_model_and_preprocessors(model_path)
    
    elif choice == 'r':
        # ì¶”ì²œ íŒŒì¼ë¡œ í…ŒìŠ¤íŠ¸
        recommended_files = [
            '../csi_data/case3/32_labeled.csv',
            '../csi_data/case2/5.csv', 
            '../csi_data/case1/40.csv',
        ]
        
        print("ğŸ¯ ì¶”ì²œ í…ŒìŠ¤íŠ¸ íŒŒì¼ë“¤:")
        for i, file_path in enumerate(recommended_files):
            exists = "âœ…" if os.path.exists(file_path) else "âŒ"
            print(f"   {i+1}. {exists} {file_path}")
        
        try:
            file_num = int(input("\níŒŒì¼ ë²ˆí˜¸ ì„ íƒ (1-5): ")) - 1
            if 0 <= file_num < len(recommended_files):
                selected_file = recommended_files[file_num]
                if os.path.exists(selected_file):
                    tester.quick_test(selected_file)
                else:
                    print(f"âŒ ì„ íƒí•œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {selected_file}")
            else:
                print("âŒ ì˜ëª»ëœ ë²ˆí˜¸ì…ë‹ˆë‹¤.")
        except ValueError:
            print("âŒ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    else:
        print("ê¸°ë³¸ê°’ìœ¼ë¡œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤...")
        tester.quick_test()

# ì¶”ê°€: ì§ì ‘ íŒŒì¼ ì§€ì •í•˜ì—¬ í…ŒìŠ¤íŠ¸í•˜ëŠ” ê°„ë‹¨í•œ í•¨ìˆ˜
def test_specific_file(csv_path):
    """íŠ¹ì • íŒŒì¼ë¡œ ë°”ë¡œ í…ŒìŠ¤íŠ¸"""
    tester = CSIModelTester()
    return tester.quick_test(csv_path)

if __name__ == "__main__":
    main()