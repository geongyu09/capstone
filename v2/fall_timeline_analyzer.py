# Python ì½”ë“œ ì‹¤í–‰ ì „ì— ì¶”ê°€
import matplotlib.pyplot as plt
import platform

# Windows
if platform.system() == "Windows":
    plt.rcParams['font.family'] = 'Malgun Gothic'  # ë§‘ì€ ê³ ë”•
    plt.rcParams['axes.unicode_minus'] = False




# fall_timeline_analyzer.py
import pandas as pd
import numpy as np
import os
import glob
import pickle
import json
from datetime import datetime, timedelta
from tensorflow.keras.models import load_model
import matplotlib.pyplot as plt
import matplotlib.dates as mdates

class FallTimelineAnalyzer:
    """ë‚™ìƒ ì‹œê°„ëŒ€ ë¶„ì„ ë° êµ¬ê°„ ê²€ì¶œê¸°"""
    
    def __init__(self, confidence_threshold=0.5, fall_duration_threshold=3):
        self.model = None
        self.scaler = None
        self.feature_selector = None
        self.metadata = None
        
        # ë¶„ì„ ì„¤ì •
        self.confidence_threshold = confidence_threshold
        self.fall_duration_threshold = fall_duration_threshold  # ìµœì†Œ ì—°ì† ê°ì§€ íšŸìˆ˜
        
        # ëª¨ë¸ ì •ë³´
        self.window_size = None
        self.stride = None
        
        # ë¶„ì„ ê²°ê³¼
        self.fall_events = []
        self.timeline_data = None
    
    def load_model_and_preprocessors(self, model_path=None):
        """ëª¨ë¸ê³¼ ì „ì²˜ë¦¬ê¸° ë¡œë“œ"""
        if model_path is None:
            # ìµœì‹  ëª¨ë¸ ìë™ íƒì§€
            model_files = glob.glob("*model*.keras") + glob.glob("*model*.h5")
            if not model_files:
                print("âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
                return False
            model_path = max(model_files, key=os.path.getctime)
        
        print(f"ğŸ“¥ ëª¨ë¸ ë¡œë”©: {os.path.basename(model_path)}")
        
        try:
            # ëª¨ë¸ ë¡œë“œ
            self.model = load_model(model_path)
            print(f"   âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            
            # ì „ì²˜ë¦¬ê¸° ë¡œë“œ
            base_path = model_path.replace('.keras', '').replace('.h5', '')
            
            # ìŠ¤ì¼€ì¼ëŸ¬
            scaler_path = base_path + '_scaler.pkl'
            if os.path.exists(scaler_path):
                with open(scaler_path, 'rb') as f:
                    self.scaler = pickle.load(f)
                print(f"   âœ… ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ")
            
            # íŠ¹ì§• ì„ íƒê¸°
            selector_path = base_path + '_selector.pkl'
            if os.path.exists(selector_path):
                with open(selector_path, 'rb') as f:
                    self.feature_selector = pickle.load(f)
                print(f"   âœ… íŠ¹ì§• ì„ íƒê¸° ë¡œë“œ ì™„ë£Œ")
            
            # ë©”íƒ€ë°ì´í„°
            metadata_path = base_path + '_metadata.json'
            if os.path.exists(metadata_path):
                with open(metadata_path, 'r', encoding='utf-8') as f:
                    self.metadata = json.load(f)
                
                self.window_size = self.metadata.get('window_size', 50)
                self.stride = self.metadata.get('stride', 5)
                print(f"   ğŸ“‹ ì„¤ì •: ìœˆë„ìš°={self.window_size}, ìŠ¤íŠ¸ë¼ì´ë“œ={self.stride}")
            else:
                self.window_size = 50
                self.stride = 5
            
            return True
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def preprocess_data(self, X):
        """ë°ì´í„° ì „ì²˜ë¦¬"""
        if self.feature_selector:
            if 'variance_selector' in self.feature_selector:
                X_var = self.feature_selector['variance_selector'].transform(X)
                if self.feature_selector.get('k_selector'):
                    X_selected = self.feature_selector['k_selector'].transform(X_var)
                else:
                    X_selected = X_var
            else:
                X_selected = X[:, 10:246] if X.shape[1] > 246 else X
        else:
            X_selected = X
        
        if self.scaler:
            X_normalized = self.scaler.transform(X_selected)
        else:
            X_normalized = X_selected
        
        return X_normalized
    
    def create_sequences_with_timestamps(self, X, timestamps):
        """íƒ€ì„ìŠ¤íƒ¬í”„ì™€ í•¨ê»˜ ì‹œí€€ìŠ¤ ìƒì„±"""
        sequences = []
        sequence_timestamps = []
        sequence_start_times = []
        sequence_end_times = []
        
        for i in range(0, len(X) - self.window_size + 1, self.stride):
            window_X = X[i:i + self.window_size]
            window_timestamps = timestamps[i:i + self.window_size]
            
            sequences.append(window_X)
            sequence_timestamps.append(window_timestamps)
            sequence_start_times.append(window_timestamps[0])
            sequence_end_times.append(window_timestamps[-1])
        
        return (np.array(sequences), 
                sequence_timestamps, 
                sequence_start_times, 
                sequence_end_times)
    
    def detect_fall_events(self, probabilities, start_times, end_times):
        """ë‚™ìƒ ì´ë²¤íŠ¸ ê°ì§€ ë° êµ¬ê°„ ë¶„ì„"""
        print("ğŸ” ë‚™ìƒ ì´ë²¤íŠ¸ êµ¬ê°„ ë¶„ì„...")
        
        # ì„ê³„ê°’ ì´ìƒì¸ ì‹œí€€ìŠ¤ë“¤ ì°¾ê¸°
        fall_mask = probabilities >= self.confidence_threshold
        fall_indices = np.where(fall_mask)[0]
        
        if len(fall_indices) == 0:
            print("   âœ… ë‚™ìƒ ì´ë²¤íŠ¸ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
        
        # ì—°ì†ëœ êµ¬ê°„ë“¤ë¡œ ê·¸ë£¹í™”
        fall_events = []
        current_event = None
        
        for i, idx in enumerate(fall_indices):
            if current_event is None:
                # ìƒˆë¡œìš´ ì´ë²¤íŠ¸ ì‹œì‘
                current_event = {
                    'start_index': idx,
                    'end_index': idx,
                    'start_time': start_times[idx],
                    'end_time': end_times[idx],
                    'max_probability': probabilities[idx],
                    'avg_probability': probabilities[idx],
                    'sequence_count': 1,
                    'probabilities': [probabilities[idx]]
                }
            else:
                # ì—°ì†ì„± í™•ì¸ (ì¸ë±ìŠ¤ ì°¨ì´ê°€ 5 ì´í•˜ë©´ ì—°ì†ìœ¼ë¡œ ê°„ì£¼)
                if idx - current_event['end_index'] <= 5:
                    # ê¸°ì¡´ ì´ë²¤íŠ¸ í™•ì¥
                    current_event['end_index'] = idx
                    current_event['end_time'] = end_times[idx]
                    current_event['max_probability'] = max(current_event['max_probability'], probabilities[idx])
                    current_event['probabilities'].append(probabilities[idx])
                    current_event['sequence_count'] += 1
                else:
                    # ì´ì „ ì´ë²¤íŠ¸ ì™„ë£Œ ë° ìƒˆ ì´ë²¤íŠ¸ ì‹œì‘
                    if current_event['sequence_count'] >= self.fall_duration_threshold:
                        current_event['avg_probability'] = np.mean(current_event['probabilities'])
                        current_event['duration_seconds'] = self._calculate_duration(
                            current_event['start_time'], current_event['end_time']
                        )
                        fall_events.append(current_event)
                    
                    current_event = {
                        'start_index': idx,
                        'end_index': idx,
                        'start_time': start_times[idx],
                        'end_time': end_times[idx],
                        'max_probability': probabilities[idx],
                        'avg_probability': probabilities[idx],
                        'sequence_count': 1,
                        'probabilities': [probabilities[idx]]
                    }
        
        # ë§ˆì§€ë§‰ ì´ë²¤íŠ¸ ì²˜ë¦¬
        if current_event and current_event['sequence_count'] >= self.fall_duration_threshold:
            current_event['avg_probability'] = np.mean(current_event['probabilities'])
            current_event['duration_seconds'] = self._calculate_duration(
                current_event['start_time'], current_event['end_time']
            )
            fall_events.append(current_event)
        
        # ê²°ê³¼ ì •ë¦¬
        for i, event in enumerate(fall_events):
            event['event_id'] = i + 1
        
        print(f"   ğŸ“Š ê°ì§€ëœ ë‚™ìƒ ì´ë²¤íŠ¸: {len(fall_events)}ê°œ")
        
        return fall_events
    
    def _calculate_duration(self, start_time, end_time):
        """ì‹œê°„ ì°¨ì´ ê³„ì‚° (ì´ˆ ë‹¨ìœ„)"""
        try:
            if isinstance(start_time, str):
                start_dt = pd.to_datetime(start_time)
                end_dt = pd.to_datetime(end_time)
            else:
                start_dt = start_time
                end_dt = end_time
            
            duration = (end_dt - start_dt).total_seconds()
            return max(duration, 0)  # ìŒìˆ˜ ë°©ì§€
        except:
            return 0
    
    def analyze_csv_timeline(self, csv_path):
        """CSV íŒŒì¼ì˜ ì „ì²´ íƒ€ì„ë¼ì¸ ë¶„ì„"""
        print(f"ğŸ“Š íƒ€ì„ë¼ì¸ ë¶„ì„ ì‹œì‘: {os.path.basename(csv_path)}")
        
        try:
            # 1. ë°ì´í„° ë¡œë“œ
            df = pd.read_csv(csv_path)
            
            print(f"   ğŸ“„ ë°ì´í„° í¬ê¸°: {df.shape}")
            
            # 2. íƒ€ì„ìŠ¤íƒ¬í”„ í˜•ì‹ í™•ì¸ ë° ì²˜ë¦¬
            print(f"   ğŸ” íƒ€ì„ìŠ¤íƒ¬í”„ í˜•ì‹ í™•ì¸...")
            
            # íƒ€ì„ìŠ¤íƒ¬í”„ ìƒ˜í”Œ í™•ì¸
            timestamp_samples = df['timestamp'].head(10).tolist()
            print(f"   ğŸ“‹ íƒ€ì„ìŠ¤íƒ¬í”„ ìƒ˜í”Œ: {timestamp_samples[:3]}")
            
            # ë‹¤ì–‘í•œ íƒ€ì„ìŠ¤íƒ¬í”„ í˜•ì‹ ì‹œë„
            timestamp_processed = False
            
            # í˜•ì‹ 1: í‘œì¤€ datetime í˜•ì‹
            try:
                df['timestamp'] = pd.to_datetime(df['timestamp'])
                print(f"   âœ… í‘œì¤€ datetime í˜•ì‹ìœ¼ë¡œ íŒŒì‹± ì„±ê³µ")
                timestamp_processed = True
            except:
                pass
            
            # í˜•ì‹ 2: ìˆ«ì í˜•íƒœ (ì´ˆ ë‹¨ìœ„)
            if not timestamp_processed:
                try:
                    # ìˆ«ìë¡œ ë³€í™˜ ì‹œë„
                    timestamp_numeric = pd.to_numeric(df['timestamp'], errors='coerce')
                    if not timestamp_numeric.isna().all():
                        # ê¸°ì¤€ ì‹œì  ì„¤ì • (í˜„ì¬ ë‚ ì§œ 00:00:00)
                        base_time = pd.Timestamp.now().normalize()
                        df['timestamp'] = base_time + pd.to_timedelta(timestamp_numeric, unit='s')
                        print(f"   âœ… ìˆ«ì(ì´ˆ) í˜•ì‹ìœ¼ë¡œ íŒŒì‹± ì„±ê³µ")
                        timestamp_processed = True
                except:
                    pass
            
            # í˜•ì‹ 3: MM:SS.f í˜•íƒœ (ë¶„:ì´ˆ.ì†Œìˆ˜)
            if not timestamp_processed:
                try:
                    def parse_mmss(time_str):
                        """MM:SS.f í˜•ì‹ì„ ì´ˆ ë‹¨ìœ„ë¡œ ë³€í™˜"""
                        if isinstance(time_str, str) and ':' in time_str:
                            parts = time_str.split(':')
                            if len(parts) == 2:
                                minutes = float(parts[0])
                                seconds = float(parts[1])
                                return minutes * 60 + seconds
                        return None
                    
                    # MM:SS í˜•ì‹ íŒŒì‹± ì‹œë„
                    timestamp_seconds = df['timestamp'].apply(parse_mmss)
                    
                    if not timestamp_seconds.isna().all():
                        # ìœ íš¨í•œ ê°’ì´ ìˆìœ¼ë©´ ë³€í™˜
                        base_time = pd.Timestamp.now().normalize()
                        df['timestamp'] = base_time + pd.to_timedelta(timestamp_seconds, unit='s')
                        print(f"   âœ… MM:SS í˜•ì‹ìœ¼ë¡œ íŒŒì‹± ì„±ê³µ")
                        timestamp_processed = True
                except Exception as e:
                    print(f"   âš ï¸ MM:SS íŒŒì‹± ì‹¤íŒ¨: {e}")
            
            # í˜•ì‹ 4: ì¸ë±ìŠ¤ ê¸°ë°˜ (íŒŒì‹± ì‹¤íŒ¨ ì‹œ)
            if not timestamp_processed:
                print(f"   âš ï¸ íƒ€ì„ìŠ¤íƒ¬í”„ íŒŒì‹± ì‹¤íŒ¨, ì¸ë±ìŠ¤ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±")
                # 0.1ì´ˆ ê°„ê²©ìœ¼ë¡œ ì¸ë±ìŠ¤ ê¸°ë°˜ íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±
                base_time = pd.Timestamp.now().normalize()
                time_intervals = pd.to_timedelta(df.index * 0.1, unit='s')
                df['timestamp'] = base_time + time_intervals
                timestamp_processed = True
            
            print(f"   â° ì‹œê°„ ë²”ìœ„: {df['timestamp'].min()} ~ {df['timestamp'].max()}")
            
            # 3. íŠ¹ì§• ì¶”ì¶œ
            feature_cols = [col for col in df.columns if col.startswith('feat_')]
            X = df[feature_cols].values
            timestamps = df['timestamp'].values
            
            print(f"   ğŸ“ˆ íŠ¹ì§• ì»¬ëŸ¼: {len(feature_cols)}ê°œ")
            
            # 4. ì „ì²˜ë¦¬
            X_processed = self.preprocess_data(X)
            
            # 5. ì‹œí€€ìŠ¤ ìƒì„±
            X_seq, seq_timestamps, start_times, end_times = self.create_sequences_with_timestamps(
                X_processed, timestamps
            )
            
            print(f"   ğŸ”„ ìƒì„±ëœ ì‹œí€€ìŠ¤: {len(X_seq)}ê°œ")
            
            # 6. ì˜ˆì¸¡ ìˆ˜í–‰
            print("   ğŸ”® ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...")
            probabilities = self.model.predict(X_seq, verbose=0).flatten()
            
            print(f"   ğŸ“Š ì˜ˆì¸¡ ì™„ë£Œ - í™•ë¥  ë²”ìœ„: {probabilities.min():.3f} ~ {probabilities.max():.3f}")
            
            # 7. ë‚™ìƒ ì´ë²¤íŠ¸ ê°ì§€
            fall_events = self.detect_fall_events(probabilities, start_times, end_times)
            
            # 8. íƒ€ì„ë¼ì¸ ë°ì´í„° ìƒì„±
            self.timeline_data = {
                'timestamps': start_times,
                'end_times': end_times,
                'probabilities': probabilities,
                'fall_mask': probabilities >= self.confidence_threshold,
                'original_timestamps': timestamps,
                'original_labels': df['label'].values if 'label' in df.columns else None
            }
            
            self.fall_events = fall_events
            
            # 9. ê²°ê³¼ ì¶œë ¥
            self.print_fall_summary()
            
            return fall_events
            
        except Exception as e:
            print(f"âŒ íƒ€ì„ë¼ì¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def print_fall_summary(self):
        """ë‚™ìƒ ì´ë²¤íŠ¸ ìš”ì•½ ì¶œë ¥"""
        print(f"\nğŸ“‹ ë‚™ìƒ ê°ì§€ ê²°ê³¼ ìš”ì•½")
        print("=" * 80)
        
        if not self.fall_events:
            print("âœ… ë‚™ìƒ ì´ë²¤íŠ¸ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # ì „ì²´ í†µê³„
            if self.timeline_data:
                max_prob = np.max(self.timeline_data['probabilities'])
                avg_prob = np.mean(self.timeline_data['probabilities'])
                print(f"ğŸ“Š ì „ì²´ í†µê³„:")
                print(f"   ìµœëŒ€ í™•ë¥ : {max_prob:.1%}")
                print(f"   í‰ê·  í™•ë¥ : {avg_prob:.1%}")
            return
        
        print(f"ğŸš¨ ì´ {len(self.fall_events)}ê°œì˜ ë‚™ìƒ ì´ë²¤íŠ¸ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤!\n")
        
        for i, event in enumerate(self.fall_events):
            print(f"ğŸ“… ë‚™ìƒ ì´ë²¤íŠ¸ #{event['event_id']}")
            print(f"   â° ì‹œì‘ ì‹œê°„: {event['start_time']}")
            print(f"   â° ì¢…ë£Œ ì‹œê°„: {event['end_time']}")
            print(f"   â±ï¸  ì§€ì† ì‹œê°„: {event['duration_seconds']:.1f}ì´ˆ")
            print(f"   ğŸ“Š ìµœëŒ€ í™•ë¥ : {event['max_probability']:.1%}")
            print(f"   ğŸ“Š í‰ê·  í™•ë¥ : {event['avg_probability']:.1%}")
            print(f"   ğŸ”¢ ì‹œí€€ìŠ¤ ìˆ˜: {event['sequence_count']}ê°œ")
            
            # ì‹ ë¢°ë„ í‰ê°€
            confidence_level = "ë†’ìŒ" if event['max_probability'] > 0.8 else \
                             "ì¤‘ê°„" if event['max_probability'] > 0.6 else "ë‚®ìŒ"
            print(f"   ğŸ¯ ì‹ ë¢°ë„: {confidence_level}")
            print()
        
        # ì „ì²´ í†µê³„
        total_fall_time = sum(event['duration_seconds'] for event in self.fall_events)
        max_prob_overall = max(event['max_probability'] for event in self.fall_events)
        avg_prob_overall = np.mean([event['avg_probability'] for event in self.fall_events])
        
        print(f"ğŸ“Š ì „ì²´ í†µê³„:")
        print(f"   ì´ ë‚™ìƒ ì‹œê°„: {total_fall_time:.1f}ì´ˆ")
        print(f"   ìµœê³  í™•ë¥ : {max_prob_overall:.1%}")
        print(f"   í‰ê·  í™•ë¥ : {avg_prob_overall:.1%}")
    
    def visualize_timeline(self, save_plot=True):
        """íƒ€ì„ë¼ì¸ ì‹œê°í™”"""
        if not self.timeline_data:
            print("âŒ íƒ€ì„ë¼ì¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
            return
        
        print("ğŸ“Š íƒ€ì„ë¼ì¸ ì‹œê°í™” ì¤‘...")
        
        fig, axes = plt.subplots(3, 1, figsize=(15, 12))
        
        timestamps = pd.to_datetime(self.timeline_data['timestamps'])
        probabilities = self.timeline_data['probabilities']
        
        # 1. ì „ì²´ í™•ë¥  íƒ€ì„ë¼ì¸
        axes[0].plot(timestamps, probabilities, linewidth=1.5, color='blue', alpha=0.7)
        axes[0].axhline(y=self.confidence_threshold, color='red', linestyle='--', 
                       alpha=0.8, label=f'ì„ê³„ê°’ ({self.confidence_threshold:.1%})')
        
        # ë‚™ìƒ êµ¬ê°„ ê°•ì¡°
        if self.fall_events:
            for event in self.fall_events:
                start_time = pd.to_datetime(event['start_time'])
                end_time = pd.to_datetime(event['end_time'])
                axes[0].axvspan(start_time, end_time, alpha=0.3, color='red',
                               label='ë‚™ìƒ êµ¬ê°„' if event == self.fall_events[0] else "")
        
        axes[0].set_title('ë‚™ìƒ í™•ë¥  íƒ€ì„ë¼ì¸')
        axes[0].set_ylabel('ë‚™ìƒ í™•ë¥ ')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)
        axes[0].xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))
        
        # 2. ë‚™ìƒ ê°ì§€ ìƒíƒœ (ì´ì§„)
        fall_binary = (probabilities >= self.confidence_threshold).astype(int)
        axes[1].fill_between(timestamps, fall_binary, alpha=0.6, color='red', 
                            step='pre', label='ë‚™ìƒ ê°ì§€')
        axes[1].set_title('ë‚™ìƒ ê°ì§€ ìƒíƒœ')
        axes[1].set_ylabel('ë‚™ìƒ ê°ì§€ (1=ê°ì§€, 0=ì •ìƒ)')
        axes[1].set_ylim(-0.1, 1.1)
        axes[1].legend()
        axes[1].grid(True, alpha=0.3)
        axes[1].xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))
        
        # 3. ì‹¤ì œ ë¼ë²¨ê³¼ ë¹„êµ (ìˆëŠ” ê²½ìš°)
        if self.timeline_data['original_labels'] is not None:
            original_timestamps = pd.to_datetime(self.timeline_data['original_timestamps'])
            original_labels = self.timeline_data['original_labels']
            
            axes[2].fill_between(original_timestamps, original_labels, alpha=0.6, 
                               color='green', step='pre', label='ì‹¤ì œ ë¼ë²¨')
            
            # ì˜ˆì¸¡ ê²°ê³¼ë„ í•¨ê»˜ í‘œì‹œ
            axes[2].fill_between(timestamps, fall_binary*0.5, alpha=0.6, 
                               color='red', step='pre', label='ì˜ˆì¸¡ ê²°ê³¼')
            
            axes[2].set_title('ì‹¤ì œ ë¼ë²¨ vs ì˜ˆì¸¡ ê²°ê³¼')
            axes[2].set_ylabel('ë¼ë²¨ (1=ë‚™ìƒ, 0=ì •ìƒ)')
            axes[2].legend()
            axes[2].grid(True, alpha=0.3)
            axes[2].xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))
        else:
            # ë‚™ìƒ ì´ë²¤íŠ¸ ìƒì„¸ ì •ë³´ í‘œì‹œ
            axes[2].bar(range(len(self.fall_events)), 
                       [event['max_probability'] for event in self.fall_events],
                       alpha=0.7, color='red')
            axes[2].set_title('ë‚™ìƒ ì´ë²¤íŠ¸ë³„ ìµœëŒ€ í™•ë¥ ')
            axes[2].set_ylabel('ìµœëŒ€ í™•ë¥ ')
            axes[2].set_xlabel('ì´ë²¤íŠ¸ ë²ˆí˜¸')
            axes[2].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_plot:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f'fall_timeline_{timestamp}.png'
            plt.savefig(filename, dpi=300, bbox_inches='tight')
            print(f"   ğŸ’¾ íƒ€ì„ë¼ì¸ ì €ì¥: {filename}")
        
        plt.show()
    
    def export_fall_events(self, output_file=None):
        """ë‚™ìƒ ì´ë²¤íŠ¸ë¥¼ íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        if not self.fall_events:
            print("ğŸ“‹ ë‚´ë³´ë‚¼ ë‚™ìƒ ì´ë²¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        if output_file is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_file = f'fall_events_{timestamp}.json'
        
        # JSON í˜•íƒœë¡œ ì €ì¥
        export_data = {
            'analysis_time': datetime.now().isoformat(),
            'settings': {
                'confidence_threshold': self.confidence_threshold,
                'fall_duration_threshold': self.fall_duration_threshold,
                'window_size': self.window_size,
                'stride': self.stride
            },
            'summary': {
                'total_events': len(self.fall_events),
                'total_fall_time': sum(event['duration_seconds'] for event in self.fall_events)
            },
            'events': []
        }
        
        for event in self.fall_events:
            event_data = {
                'event_id': event['event_id'],
                'start_time': event['start_time'].isoformat() if hasattr(event['start_time'], 'isoformat') else str(event['start_time']),
                'end_time': event['end_time'].isoformat() if hasattr(event['end_time'], 'isoformat') else str(event['end_time']),
                'duration_seconds': event['duration_seconds'],
                'max_probability': float(event['max_probability']),
                'avg_probability': float(event['avg_probability']),
                'sequence_count': int(event['sequence_count'])
            }
            export_data['events'].append(event_data)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“„ ë‚™ìƒ ì´ë²¤íŠ¸ ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {output_file}")
        return output_file

def analyze_fall_timeline(csv_path, confidence_threshold=0.5):
    """ë¹ ë¥¸ ë‚™ìƒ íƒ€ì„ë¼ì¸ ë¶„ì„"""
    analyzer = FallTimelineAnalyzer(confidence_threshold=confidence_threshold)
    
    if not analyzer.load_model_and_preprocessors():
        return None
    
    fall_events = analyzer.analyze_csv_timeline(csv_path)
    
    if fall_events:
        analyzer.visualize_timeline()
        analyzer.export_fall_events()
    
    return analyzer

if __name__ == "__main__":
    import sys
    
    print("ğŸ“Š ë‚™ìƒ íƒ€ì„ë¼ì¸ ë¶„ì„ê¸°")
    print("=" * 40)
    
    if len(sys.argv) > 1:
        csv_file = sys.argv[1]
        confidence = float(sys.argv[2]) if len(sys.argv) > 2 else 0.5
    else:
        # í…ŒìŠ¤íŠ¸ íŒŒì¼ë“¤
        test_files = [
            "../csi_data/case1/12_labeled.csv",
        ]
        
        csv_file = None
        for file_path in test_files:
            if os.path.exists(file_path):
                csv_file = file_path
                break
        
        if not csv_file:
            print("âŒ í…ŒìŠ¤íŠ¸í•  CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
            print("ì‚¬ìš©ë²•: python fall_timeline_analyzer.py <csv_file> [confidence_threshold]")
            exit(1)
        
        confidence = 0.5
    
    print(f"ğŸ“„ ë¶„ì„ íŒŒì¼: {csv_file}")
    print(f"ğŸ¯ ì‹ ë¢°ë„ ì„ê³„ê°’: {confidence}")
    
    analyzer = analyze_fall_timeline(csv_file, confidence)
    
    if analyzer and analyzer.fall_events:
        print(f"\nğŸ‰ ë¶„ì„ ì™„ë£Œ! {len(analyzer.fall_events)}ê°œì˜ ë‚™ìƒ ì´ë²¤íŠ¸ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("âœ… ë‚™ìƒ ì´ë²¤íŠ¸ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")