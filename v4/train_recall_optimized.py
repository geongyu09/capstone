"""
ë°ì´í„° ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ Recall ìµœì í™” í•™ìŠµ
- ë°ì´í„°ëŠ” ì¶©ë¶„ (ë‚™ìƒ 64.38%)
- ë¬¸ì œëŠ” ëª¨ë¸/í•™ìŠµ ì„¤ì •ì— ìˆìŒ
"""

import os
import sys
import numpy as np
from datetime import datetime

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# ìµœì í™”ëœ config ì‚¬ìš©
import config_optimized as Config
from config_optimized import Config as Cfg, ModelConfig
from utils import setup_logging, create_timestamp
from data_generator import create_data_generators
from improved_model_fixed import build_improved_model, FocalLoss

def create_optimized_model():
    """ìµœì í™”ëœ Recall ëª¨ë¸ ìƒì„±"""
    
    logger = setup_logging()
    logger.info("ğŸ¯ Recall ìµœì í™” ëª¨ë¸ ìƒì„±")
    
    # ì…ë ¥ í˜•íƒœ
    input_shape = (Cfg.WINDOW_SIZE, Cfg.TOTAL_FEATURES)
    
    # í–¥ìƒëœ ëª¨ë¸ êµ¬ì¶• (ë“œë¡­ì•„ì›ƒ ì™„í™”)
    model = build_improved_model(input_shape)
    
    # ì»¤ìŠ¤í…€ ì»´íŒŒì¼
    from tensorflow.keras.optimizers import Adam
    import tensorflow as tf
    
    # ì˜µí‹°ë§ˆì´ì € (ì•ˆì •ì  í•™ìŠµ)
    optimizer = Adam(
        learning_rate=Cfg.LEARNING_RATE,
        beta_1=0.9,
        beta_2=0.999,
        epsilon=1e-7
    )
    
    # ì ë‹¹í•œ Focal Loss
    focal_loss = FocalLoss(
        alpha=Cfg.FOCAL_LOSS_ALPHA,
        gamma=Cfg.FOCAL_LOSS_GAMMA
    )
    
    # ìƒì„¸í•œ ë©”íŠ¸ë¦­
    metrics = [
        'accuracy',
        tf.keras.metrics.Precision(name='precision'),
        tf.keras.metrics.Recall(name='recall'),
        tf.keras.metrics.AUC(name='auc'),
        tf.keras.metrics.TruePositives(name='tp'),
        tf.keras.metrics.FalseNegatives(name='fn'),
        tf.keras.metrics.FalsePositives(name='fp'),
        tf.keras.metrics.TrueNegatives(name='tn')
    ]
    
    model.compile(
        optimizer=optimizer,
        loss=focal_loss,
        metrics=metrics
    )
    
    logger.info("âœ… ìµœì í™”ëœ ëª¨ë¸ ì»´íŒŒì¼ ì™„ë£Œ")
    logger.info(f"   í•™ìŠµë¥ : {Cfg.LEARNING_RATE}")
    logger.info(f"   Focal Loss: Î±={Cfg.FOCAL_LOSS_ALPHA}, Î³={Cfg.FOCAL_LOSS_GAMMA}")
    
    return model

def train_optimized_model():
    """ìµœì í™”ëœ ì„¤ì •ìœ¼ë¡œ í•™ìŠµ"""
    
    logger = setup_logging()
    logger.info("ğŸš€ Recall ìµœì í™” í•™ìŠµ ì‹œì‘")
    
    try:
        # 1. ë°ì´í„° ì œë„ˆë ˆì´í„°
        logger.info("ğŸ“Š ë°ì´í„° ì œë„ˆë ˆì´í„° ì¤€ë¹„...")
        
        # Config ì„¤ì •
        import config
        config.Config.OVERLAP_THRESHOLD = Cfg.OVERLAP_THRESHOLD
        config.Config.BATCH_SIZE = Cfg.BATCH_SIZE
        
        train_gen, val_gen, test_gen = create_data_generators()
        
        logger.info(f"   í›ˆë ¨ ì‹œí€€ìŠ¤: {train_gen.total_sequences:,}ê°œ")
        logger.info(f"   ê²€ì¦ ì‹œí€€ìŠ¤: {val_gen.total_sequences:,}ê°œ")
        logger.info(f"   í…ŒìŠ¤íŠ¸ ì‹œí€€ìŠ¤: {test_gen.total_sequences:,}ê°œ")
        
        # í´ë˜ìŠ¤ ë¶„í¬ ì¬í™•ì¸
        logger.info("ğŸ“ˆ í´ë˜ìŠ¤ ë¶„í¬ ì¬í™•ì¸...")
        sample_labels = []
        for i in range(min(3, len(train_gen))):
            _, y_batch = train_gen[i]
            sample_labels.extend(y_batch)
        
        if sample_labels:
            fall_ratio = np.mean(sample_labels)
            logger.info(f"   ë‚™ìƒ ë¹„ìœ¨: {fall_ratio*100:.1f}% (ì˜ˆìƒ: ~64%)")
        
        # 2. ìµœì í™”ëœ ëª¨ë¸ ìƒì„±
        logger.info("ğŸ§  ìµœì í™”ëœ ëª¨ë¸ êµ¬ì¶•...")
        model = create_optimized_model()
        
        print("\nğŸ“‹ ìµœì í™”ëœ ëª¨ë¸ ìš”ì•½:")
        model.summary()
        
        # 3. í•™ìŠµ ì½œë°± (Recall ì¤‘ì‹¬)
        from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, Callback
        
        class DetailedMonitor(Callback):
            """ìƒì„¸í•œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§"""
            def __init__(self):
                super().__init__()
                self.best_recall = 0
                self.epochs_since_improvement = 0
                
            def on_epoch_end(self, epoch, logs=None):
                # ì£¼ìš” ë©”íŠ¸ë¦­ ì¶”ì¶œ
                val_recall = logs.get('val_recall', 0)
                val_precision = logs.get('val_precision', 0)
                val_accuracy = logs.get('val_accuracy', 0)
                val_loss = logs.get('val_loss', 0)
                
                # F1 Score ê³„ì‚°
                if val_precision + val_recall > 0:
                    f1 = 2 * (val_precision * val_recall) / (val_precision + val_recall)
                else:
                    f1 = 0
                
                # ì§„í–‰ìƒí™© ì¶œë ¥
                print(f\"\\nğŸ“Š Epoch {epoch+1} ê²°ê³¼:\")\n                print(f\"   Recall: {val_recall:.4f} | Precision: {val_precision:.4f} | F1: {f1:.4f}\")\n                print(f\"   Accuracy: {val_accuracy:.4f} | Loss: {val_loss:.4f}\")\n                \n                # Recall ê°œì„  í™•ì¸\n                if val_recall > self.best_recall:\n                    improvement = val_recall - self.best_recall\n                    self.best_recall = val_recall\n                    self.epochs_since_improvement = 0\n                    print(f\"   ğŸ¯ ìƒˆë¡œìš´ ìµœê³  Recall! (+{improvement:.4f})\")\n                else:\n                    self.epochs_since_improvement += 1\n                    if self.epochs_since_improvement >= 5:\n                        print(f\"   âš ï¸ {self.epochs_since_improvement}ë²ˆì§¸ ì—í¬í¬ ë™ì•ˆ Recall ê°œì„  ì—†ìŒ\")\n                \n                # ëª©í‘œ ë‹¬ì„± í™•ì¸\n                if val_recall >= 0.8:\n                    print(\"   ğŸ‰ ëª©í‘œ Recall 80% ë‹¬ì„±!\")\n                elif val_recall >= 0.7:\n                    print(\"   âœ… ì–‘í˜¸í•œ Recall 70% ì´ìƒ\")\n                elif val_recall >= 0.5:\n                    print(\"   ğŸ‘ ê´œì°®ì€ Recall 50% ì´ìƒ\")\n                elif val_recall < 0.3 and epoch > 10:\n                    print(\"   ğŸš¨ Recallì´ ì—¬ì „íˆ ë‚®ìŠµë‹ˆë‹¤. ì„¤ì • ì¬ê²€í†  í•„ìš”\")\n        \n        experiment_name = f\"recall_optimized_{create_timestamp()}\"\n        \n        callbacks = [\n            DetailedMonitor(),\n            \n            # Recall ê¸°ì¤€ Early Stopping (ì—¬ìœ ìˆê²Œ)\n            EarlyStopping(\n                monitor='val_recall',\n                patience=20,  # ì¶©ë¶„í•œ ì‹œê°„\n                mode='max',\n                restore_best_weights=True,\n                verbose=1\n            ),\n            \n            # ëª¨ë¸ ì €ì¥ (Recall ê¸°ì¤€)\n            ModelCheckpoint(\n                filepath=f\"./models/{experiment_name}_best.keras\",\n                monitor='val_recall',\n                save_best_only=True,\n                mode='max',\n                verbose=1\n            ),\n            \n            # í•™ìŠµë¥  ê°ì†Œ (ì ì§„ì )\n            ReduceLROnPlateau(\n                monitor='val_recall',\n                factor=0.7,  # ë” ë¶€ë“œëŸ½ê²Œ\n                patience=10,\n                mode='max',\n                min_lr=1e-6,\n                verbose=1\n            )\n        ]\n        \n        # 4. í•™ìŠµ ì‹¤í–‰\n        logger.info(f\"ğŸ‹ï¸ ìµœì í™”ëœ í•™ìŠµ ì‹œì‘ (ì‹¤í—˜ëª…: {experiment_name})\")\n        logger.info(f\"   ì—í¬í¬: {Cfg.EPOCHS}\")\n        logger.info(f\"   ì˜ˆìƒ ì‹œê°„: 1-2ì‹œê°„\")\n        \n        # í•™ìŠµ ì§„í–‰\n        history = model.fit(\n            train_gen,\n            validation_data=val_gen,\n            epochs=Cfg.EPOCHS,\n            callbacks=callbacks,\n            verbose=1,\n            class_weight=Cfg.CLASS_WEIGHTS\n        )\n        \n        # 5. ê²°ê³¼ ë¶„ì„\n        logger.info(\"ğŸ“Š í•™ìŠµ ê²°ê³¼ ë¶„ì„...\")\n        \n        best_recall = max(history.history.get('val_recall', [0]))\n        best_precision = max(history.history.get('val_precision', [0]))\n        best_accuracy = max(history.history.get('val_accuracy', [0]))\n        \n        # F1 Score ê³„ì‚°\n        val_recalls = history.history.get('val_recall', [0])\n        val_precisions = history.history.get('val_precision', [0])\n        f1_scores = []\n        for r, p in zip(val_recalls, val_precisions):\n            if r + p > 0:\n                f1_scores.append(2 * (r * p) / (r + p))\n            else:\n                f1_scores.append(0)\n        best_f1 = max(f1_scores) if f1_scores else 0\n        \n        logger.info(f\"âœ… ìµœì í™” í•™ìŠµ ì™„ë£Œ!\")\n        logger.info(f\"   ìµœê³  Recall: {best_recall:.4f}\")\n        logger.info(f\"   ìµœê³  Precision: {best_precision:.4f}\")\n        logger.info(f\"   ìµœê³  F1 Score: {best_f1:.4f}\")\n        logger.info(f\"   ìµœê³  Accuracy: {best_accuracy:.4f}\")\n        \n        # ì„±ê³¼ í‰ê°€\n        if best_recall >= 0.8:\n            logger.info(\"ğŸ‰ íƒì›”í•œ ì„±ê³¼! Recall 80% ì´ìƒ ë‹¬ì„±\")\n            success_level = \"excellent\"\n        elif best_recall >= 0.7:\n            logger.info(\"ğŸŒŸ í›Œë¥­í•œ ì„±ê³¼! Recall 70% ì´ìƒ ë‹¬ì„±\")\n            success_level = \"great\"\n        elif best_recall >= 0.5:\n            logger.info(\"ğŸ‘ ì¢‹ì€ ì„±ê³¼! Recall 50% ì´ìƒ ë‹¬ì„±\")\n            success_level = \"good\"\n        elif best_recall >= 0.3:\n            logger.info(\"ğŸ“ˆ ê°œì„ ë¨! Recall 30% ì´ìƒ ë‹¬ì„±\")\n            success_level = \"improved\"\n        else:\n            logger.warning(\"ğŸ¤” ì¶”ê°€ ìµœì í™” í•„ìš”. Recallì´ ì•„ì§ ë‚®ìŒ\")\n            success_level = \"needs_work\"\n        \n        # 6. ë©”íƒ€ë°ì´í„° ì €ì¥\n        import json\n        \n        metadata = {\n            'experiment_name': experiment_name,\n            'model_type': 'recall_optimized_hybrid',\n            'timestamp': create_timestamp(),\n            'data_analysis': {\n                'fall_sequences_ratio': '64.38%',\n                'data_balance': 'good',\n                'problem_identified': 'model_training_settings'\n            },\n            'optimizations': [\n                f'í•™ìŠµë¥  ìµœì í™”: {Cfg.LEARNING_RATE}',\n                f'ì ë‹¹í•œ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜: {Cfg.CLASS_WEIGHTS}',\n                f'ë“œë¡­ì•„ì›ƒ ì™„í™”',\n                f'ì•ˆì •ì  Focal Loss: Î±={Cfg.FOCAL_LOSS_ALPHA}, Î³={Cfg.FOCAL_LOSS_GAMMA}',\n                f'ì¶©ë¶„í•œ ì—í¬í¬: {Cfg.EPOCHS}'\n            ],\n            'results': {\n                'best_recall': float(best_recall),\n                'best_precision': float(best_precision),\n                'best_f1_score': float(best_f1),\n                'best_accuracy': float(best_accuracy),\n                'success_level': success_level,\n                'epochs_trained': len(history.history['loss'])\n            }\n        }\n        \n        # ë©”íƒ€ë°ì´í„° ì €ì¥\n        metadata_path = f\"./models/{experiment_name}_metadata.json\"\n        with open(metadata_path, 'w', encoding='utf-8') as f:\n            json.dump(metadata, f, indent=2, ensure_ascii=False)\n        \n        logger.info(f\"ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {metadata_path}\")\n        \n        return experiment_name, history, metadata\n        \n    except Exception as e:\n        logger.error(f\"âŒ ìµœì í™” í•™ìŠµ ì‹¤íŒ¨: {e}\")\n        import traceback\n        traceback.print_exc()\n        return None, None, None\n\ndef quick_test():\n    \"\"\"ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (10 ì—í¬í¬)\"\"\"\n    print(\"ğŸ§ª ë¹ ë¥¸ ìµœì í™” í…ŒìŠ¤íŠ¸ (10 ì—í¬í¬)\")\n    \n    original_epochs = Cfg.EPOCHS\n    Cfg.EPOCHS = 10\n    \n    try:\n        experiment_name, history, metadata = train_optimized_model()\n        \n        if history and 'val_recall' in history.history:\n            final_recall = history.history['val_recall'][-1]\n            max_recall = max(history.history['val_recall'])\n            \n            print(f\"\\nğŸ¯ 10 ì—í¬í¬ ê²°ê³¼:\")\n            print(f\"   ìµœì¢… Recall: {final_recall:.4f}\")\n            print(f\"   ìµœê³  Recall: {max_recall:.4f}\")\n            \n            if max_recall > 0.4:\n                print(\"âœ… ì¢‹ì€ ì‹œì‘! ì „ì²´ í•™ìŠµì„ ì§„í–‰í•˜ì„¸ìš”.\")\n                return True\n            elif max_recall > 0.2:\n                print(\"ğŸ“ˆ ê°œì„  ì¤‘! ë” ê¸´ í•™ìŠµì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n                return True\n            else:\n                print(\"âš ï¸ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤. ì„¤ì •ì„ ë‹¤ì‹œ ê²€í† í•˜ì„¸ìš”.\")\n                return False\n        else:\n            print(\"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨\")\n            return False\n    finally:\n        Cfg.EPOCHS = original_epochs\n\ndef main():\n    \"\"\"ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜\"\"\"\n    \n    print(\"ğŸ¯ CSI ë‚™ìƒ ê°ì§€ Recall ìµœì í™” í•™ìŠµ\")\n    print(\"=\" * 50)\n    \n    # ë¶„ì„ ê²°ê³¼ ìš”ì•½\n    print(\"ğŸ“Š ë°ì´í„° ë¶„ì„ ê²°ê³¼ ìš”ì•½:\")\n    print(\"   âœ… ë‚™ìƒ ì‹œí€€ìŠ¤: 64.38% (ì¶©ë¶„í•¨!)\")\n    print(\"   âœ… í´ë˜ìŠ¤ ë¶ˆê· í˜•: ì‹¬ê°í•˜ì§€ ì•ŠìŒ\")\n    print(\"   ğŸ¯ ë¬¸ì œ: ëª¨ë¸/í•™ìŠµ ì„¤ì •\")\n    print(\"   ğŸ’¡ í•´ê²°: ì•ˆì •ì  í•™ìŠµ + ì ë‹¹í•œ ê°€ì¤‘ì¹˜\")\n    \n    # ìµœì í™”ëœ ì„¤ì • ì¶œë ¥\n    Cfg.print_config()\n    \n    print(\"\\nğŸ¤” ì–´ë–¤ ì‘ì—…ì„ ìˆ˜í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?\")\n    print(\"1. ë¹ ë¥¸ ìµœì í™” í…ŒìŠ¤íŠ¸ (10 ì—í¬í¬, ì¶”ì²œ)\")\n    print(\"2. ì „ì²´ ìµœì í™” í•™ìŠµ (80 ì—í¬í¬)\")\n    print(\"3. ì„¤ì •ë§Œ í™•ì¸\")\n    \n    choice = input(\"\\nì„ íƒ (1-3): \").strip()\n    \n    if choice == \"1\":\n        success = quick_test()\n        \n        if success:\n            full_train = input(\"\\nì „ì²´ í•™ìŠµì„ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): \").lower()\n            if full_train == 'y':\n                train_optimized_model()\n        \n    elif choice == \"2\":\n        print(\"\\nğŸ‹ï¸ ì „ì²´ ìµœì í™” í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n        print(\"â° ì˜ˆìƒ ì†Œìš”ì‹œê°„: 1-2ì‹œê°„\")\n        \n        confirm = input(\"ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): \").lower()\n        if confirm == 'y':\n            experiment_name, history, metadata = train_optimized_model()\n            \n            if metadata:\n                success_level = metadata['results']['success_level']\n                best_recall = metadata['results']['best_recall']\n                \n                print(f\"\\nğŸ¯ ìµœì¢… ê²°ê³¼: {success_level}\")\n                print(f\"   ìµœê³  Recall: {best_recall:.4f}\")\n                \n                if success_level in ['excellent', 'great', 'good']:\n                    print(\"\\nğŸ‰ Recall ë¬¸ì œê°€ í•´ê²°ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n                else:\n                    print(\"\\nğŸ“ˆ ê°œì„ ë˜ì—ˆì§€ë§Œ ì¶”ê°€ íŠœë‹ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n        \n    elif choice == \"3\":\n        print(\"\\nâœ… ì„¤ì • í™•ì¸ ì™„ë£Œ\")\n        \n    else:\n        print(\"ì˜¬ë°”ë¥¸ ì„ íƒì´ ì•„ë‹™ë‹ˆë‹¤.\")\n\nif __name__ == \"__main__\":\n    main()\n