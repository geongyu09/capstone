"""
CSI ë‚™ìƒ ê°ì§€ v4 - ëª¨ë¸ í•™ìŠµê¸°
"""

import os
import time
from datetime import datetime
from typing import Dict, Any, Tuple, Optional
import numpy as np
import tensorflow as tf

from config import Config
from utils import (
    setup_logging, save_model_artifacts, create_timestamp,
    calculate_class_weights, format_time, memory_usage_mb,
    plot_training_history
)
from data_generator import create_data_generators
from model_builder import create_model


class CSIModelTrainer:
    """CSI ë‚™ìƒ ê°ì§€ ëª¨ë¸ í•™ìŠµê¸°"""
    
    def __init__(self, 
                 model_type: str = 'hybrid',
                 experiment_name: Optional[str] = None,
                 logger=None):
        """
        Args:
            model_type: ëª¨ë¸ íƒ€ì… ('hybrid', 'simple', 'cnn')
            experiment_name: ì‹¤í—˜ ì´ë¦„ (Noneì´ë©´ ìë™ ìƒì„±)
            logger: ë¡œê±° ê°ì²´
        """
        self.model_type = model_type
        self.experiment_name = experiment_name or f"{model_type}_{create_timestamp()}"
        self.logger = logger or setup_logging()
        
        # ì´ˆê¸°í™”
        self.model = None
        self.model_builder = None
        self.train_gen = None
        self.val_gen = None
        self.test_gen = None
        self.history = None
        self.class_weights = None
        
        self.logger.info(f"ğŸš€ ëª¨ë¸ í•™ìŠµê¸° ì´ˆê¸°í™”")
        self.logger.info(f"   ëª¨ë¸ íƒ€ì…: {self.model_type}")
        self.logger.info(f"   ì‹¤í—˜ ì´ë¦„: {self.experiment_name}")
    
    def prepare_data(self) -> None:
        """ë°ì´í„° ì œë„ˆë ˆì´í„° ì¤€ë¹„"""
        self.logger.info("ğŸ“Š ë°ì´í„° ì œë„ˆë ˆì´í„° ì¤€ë¹„ ì¤‘...")
        
        start_time = time.time()
        
        # ë°ì´í„° ì œë„ˆë ˆì´í„° ìƒì„±
        self.train_gen, self.val_gen, self.test_gen = create_data_generators()
        
        # í†µê³„ ì¶œë ¥
        self.logger.info("âœ… ë°ì´í„° ì œë„ˆë ˆì´í„° ì¤€ë¹„ ì™„ë£Œ")
        self.logger.info(f"   í›ˆë ¨ ì‹œí€€ìŠ¤: {self.train_gen.total_sequences:,}ê°œ")
        self.logger.info(f"   ê²€ì¦ ì‹œí€€ìŠ¤: {self.val_gen.total_sequences:,}ê°œ")
        self.logger.info(f"   í…ŒìŠ¤íŠ¸ ì‹œí€€ìŠ¤: {self.test_gen.total_sequences:,}ê°œ")
        
        # í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸ (ìƒ˜í”Œë§)
        self.logger.info("ğŸ“ˆ í´ë˜ìŠ¤ ë¶„í¬ ë¶„ì„ ì¤‘ (ìƒ˜í”Œë§)...")
        sample_labels = []
        sample_size = min(1000, len(self.train_gen.sequences))
        
        for i in range(0, sample_size, 10):  # 10ê°œì”© ê±´ë„ˆë›°ë©° ìƒ˜í”Œë§
            try:
                file_path, start_idx, end_idx = self.train_gen.sequences[i]
                _, y = self.train_gen._load_sequence(file_path, start_idx, end_idx)
                sample_labels.append(y)
            except:
                continue
        
        if sample_labels:
            sample_labels = np.array(sample_labels)
            fall_ratio = np.mean(sample_labels)
            self.logger.info(f"   ìƒ˜í”Œ í´ë˜ìŠ¤ ë¶„í¬: ì •ìƒ {1-fall_ratio:.3f}, ë‚™ìƒ {fall_ratio:.3f}")
            
            # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
            self.class_weights = calculate_class_weights(sample_labels)
            self.logger.info(f"   í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜: {self.class_weights}")
        
        elapsed_time = time.time() - start_time
        self.logger.info(f"   ì¤€ë¹„ ì‹œê°„: {format_time(elapsed_time)}")
    
    def build_model(self) -> None:
        """ëª¨ë¸ êµ¬ì¶• ë° ì»´íŒŒì¼"""
        self.logger.info(f"ğŸ§  {self.model_type} ëª¨ë¸ êµ¬ì¶• ì¤‘...")
        
        # ì…ë ¥ í˜•íƒœ ì„¤ì •
        input_shape = (Config.WINDOW_SIZE, Config.TOTAL_FEATURES)
        
        # ëª¨ë¸ ìƒì„±
        self.model, self.model_builder = create_model(
            model_type=self.model_type,
            input_shape=input_shape,
            learning_rate=Config.LEARNING_RATE,
            class_weights=self.class_weights
        )
        
        # ëª¨ë¸ ìš”ì•½ ì¶œë ¥
        self.model_builder.print_model_summary()
        
        self.logger.info("âœ… ëª¨ë¸ êµ¬ì¶• ì™„ë£Œ")
    
    def train(self, 
              epochs: int = Config.EPOCHS,
              patience: int = 10,
              save_best: bool = True) -> Dict[str, Any]:
        """ëª¨ë¸ í•™ìŠµ"""
        
        if self.model is None:
            raise ValueError("ëª¨ë¸ì´ êµ¬ì¶•ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. build_model()ì„ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
        
        if self.train_gen is None:
            raise ValueError("ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. prepare_data()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
        
        self.logger.info(f"ğŸ‹ï¸ ëª¨ë¸ í•™ìŠµ ì‹œì‘")
        self.logger.info(f"   ì—í¬í¬: {epochs}")
        self.logger.info(f"   ì¡°ê¸° ì¢…ë£Œ patience: {patience}")
        self.logger.info(f"   ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_usage_mb():.1f} MB")
        
        # ì½œë°± ì„¤ì •
        callbacks = self.model_builder.get_callbacks(
            model_name=self.experiment_name,
            patience=patience
        )
        
        # í•™ìŠµ ì‹œì‘
        start_time = time.time()
        
        try:
            self.history = self.model.fit(
                self.train_gen,
                validation_data=self.val_gen,
                epochs=epochs,
                callbacks=callbacks,
                verbose=1
            )
            
            # í•™ìŠµ ì™„ë£Œ
            training_time = time.time() - start_time
            self.logger.info(f"âœ… í•™ìŠµ ì™„ë£Œ!")
            self.logger.info(f"   ì´ í•™ìŠµ ì‹œê°„: {format_time(training_time)}")
            self.logger.info(f"   ìµœì¢… ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_usage_mb():.1f} MB")
            
            # ìµœê³  ì„±ëŠ¥ ì—í¬í¬ ì •ë³´
            best_epoch = np.argmin(self.history.history['val_loss']) + 1
            best_val_loss = np.min(self.history.history['val_loss'])
            best_val_acc = self.history.history['val_accuracy'][best_epoch - 1]
            
            self.logger.info(f"   ìµœê³  ì„±ëŠ¥ ì—í¬í¬: {best_epoch}")
            self.logger.info(f"   ìµœê³  ê²€ì¦ ì†ì‹¤: {best_val_loss:.4f}")
            self.logger.info(f"   ìµœê³  ê²€ì¦ ì •í™•ë„: {best_val_acc:.4f}")
            
            # ëª¨ë¸ ì €ì¥
            if save_best:
                self._save_model()
            
            # í•™ìŠµ íˆìŠ¤í† ë¦¬ ì‹œê°í™”
            self._plot_training_results()
            
            return {
                'history': self.history.history,
                'training_time': training_time,
                'best_epoch': best_epoch,
                'best_val_loss': best_val_loss,
                'best_val_accuracy': best_val_acc,
                'experiment_name': self.experiment_name
            }
            
        except KeyboardInterrupt:
            self.logger.info("â¹ï¸ í•™ìŠµì´ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return None
            
        except Exception as e:
            self.logger.error(f"âŒ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise
    
    def evaluate(self) -> Dict[str, Any]:
        """í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ëª¨ë¸ í‰ê°€"""
        
        if self.model is None:
            raise ValueError("ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        if self.test_gen is None:
            raise ValueError("í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        self.logger.info("ğŸ“Š ëª¨ë¸ í‰ê°€ ì‹œì‘...")
        
        # í‰ê°€ ì‹¤í–‰
        start_time = time.time()
        test_results = self.model.evaluate(self.test_gen, verbose=1)
        evaluation_time = time.time() - start_time
        
        # ê²°ê³¼ ì •ë¦¬
        metric_names = self.model.metrics_names
        results = dict(zip(metric_names, test_results))
        
        self.logger.info(f"âœ… í‰ê°€ ì™„ë£Œ (ì‹œê°„: {format_time(evaluation_time)})")
        self.logger.info(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
        for metric, value in results.items():
            self.logger.info(f"   {metric}: {value:.4f}")
        
        return {
            'test_results': results,
            'evaluation_time': evaluation_time,
            'experiment_name': self.experiment_name
        }
    
    def _save_model(self) -> None:
        """ëª¨ë¸ ë° ê´€ë ¨ íŒŒì¼ë“¤ ì €ì¥"""
        self.logger.info("ğŸ’¾ ëª¨ë¸ ì €ì¥ ì¤‘...")
        
        # ë©”íƒ€ë°ì´í„° ìƒì„±
        metadata = {
            'experiment_name': self.experiment_name,
            'model_type': self.model_type,
            'timestamp': create_timestamp(),
            'config': {
                'window_size': Config.WINDOW_SIZE,
                'stride': Config.STRIDE,
                'batch_size': Config.BATCH_SIZE,
                'learning_rate': Config.LEARNING_RATE,
                'total_features': Config.TOTAL_FEATURES
            },
            'model_config': self.model_builder.model_config,
            'class_weights': self.class_weights,
            'input_shape': self.model.input_shape[1:],  # ë°°ì¹˜ ì°¨ì› ì œì™¸
            'training_samples': self.train_gen.total_sequences if self.train_gen else 0,
            'validation_samples': self.val_gen.total_sequences if self.val_gen else 0,
            'test_samples': self.test_gen.total_sequences if self.test_gen else 0
        }
        
        # í•™ìŠµ íˆìŠ¤í† ë¦¬ ì¶”ê°€
        if self.history:
            metadata['training_history'] = {
                'epochs': len(self.history.history['loss']),
                'final_train_loss': float(self.history.history['loss'][-1]),
                'final_val_loss': float(self.history.history['val_loss'][-1]),
                'best_val_loss': float(np.min(self.history.history['val_loss'])),
                'best_epoch': int(np.argmin(self.history.history['val_loss']) + 1)
            }
        
        # íŒŒì¼ ì €ì¥ (ìŠ¤ì¼€ì¼ëŸ¬ëŠ” ì „ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ ì´ë¯¸ ì €ì¥ë¨)
        try:
            saved_paths = save_model_artifacts(
                model=self.model,
                scaler=None,  # ì „ì²˜ë¦¬ì—ì„œ ë³„ë„ ê´€ë¦¬
                metadata=metadata,
                model_dir=Config.MODEL_DIR,
                model_name=self.experiment_name
            )
            
            self.logger.info("âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ")
            for artifact_type, path in saved_paths.items():
                self.logger.info(f"   {artifact_type}: {path}")
                
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _plot_training_results(self) -> None:
        """í•™ìŠµ ê²°ê³¼ ì‹œê°í™”"""
        if self.history is None:
            return
        
        try:
            # ì €ì¥ ê²½ë¡œ
            plot_path = os.path.join(Config.LOG_DIR, f"{self.experiment_name}_training_history.png")
            
            # í”Œë¡¯ ìƒì„±
            plot_training_history(self.history.history, save_path=plot_path)
            
            self.logger.info(f"ğŸ“Š í•™ìŠµ íˆìŠ¤í† ë¦¬ ì €ì¥: {plot_path}")
            
        except Exception as e:
            self.logger.warning(f"í•™ìŠµ íˆìŠ¤í† ë¦¬ ì‹œê°í™” ì‹¤íŒ¨: {e}")
    
    def run_complete_training(self, 
                            epochs: int = Config.EPOCHS,
                            patience: int = 10,
                            evaluate_after_training: bool = True) -> Dict[str, Any]:
        """ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        
        self.logger.info(f"ğŸš€ ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹œì‘: {self.experiment_name}")
        
        start_time = time.time()
        results = {}
        
        try:
            # 1. ë°ì´í„° ì¤€ë¹„
            self.prepare_data()
            
            # 2. ëª¨ë¸ êµ¬ì¶•
            self.build_model()
            
            # 3. í•™ìŠµ
            training_results = self.train(epochs=epochs, patience=patience)
            if training_results:
                results.update(training_results)
            
            # 4. í‰ê°€ (ì„ íƒì )
            if evaluate_after_training and training_results:
                eval_results = self.evaluate()
                results.update(eval_results)
            
            # ì´ ì†Œìš” ì‹œê°„
            total_time = time.time() - start_time
            results['total_time'] = total_time
            
            self.logger.info(f"ğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
            self.logger.info(f"   ì´ ì†Œìš” ì‹œê°„: {format_time(total_time)}")
            
            return results
            
        except Exception as e:
            self.logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            raise


def train_model(model_type: str = 'hybrid',
               experiment_name: Optional[str] = None,
               epochs: int = Config.EPOCHS,
               patience: int = 10) -> Dict[str, Any]:
    """ëª¨ë¸ í•™ìŠµ í—¬í¼ í•¨ìˆ˜"""
    
    trainer = CSIModelTrainer(
        model_type=model_type,
        experiment_name=experiment_name
    )
    
    return trainer.run_complete_training(
        epochs=epochs,
        patience=patience,
        evaluate_after_training=True
    )


if __name__ == "__main__":
    # í•™ìŠµ í…ŒìŠ¤íŠ¸
    print("ğŸ§ª CSI ëª¨ë¸ í•™ìŠµê¸° í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # ì„¤ì • ì¶œë ¥
    print(f"í•™ìŠµ ì„¤ì •:")
    print(f"  ìœˆë„ìš° í¬ê¸°: {Config.WINDOW_SIZE}")
    print(f"  ë°°ì¹˜ í¬ê¸°: {Config.BATCH_SIZE}")
    print(f"  ì—í¬í¬: {Config.EPOCHS}")
    print(f"  í•™ìŠµë¥ : {Config.LEARNING_RATE}")
    
    # ì‚¬ìš©ì í™•ì¸
    choice = input("\ní…ŒìŠ¤íŠ¸ í•™ìŠµì„ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower().strip()
    
    if choice == 'y':
        try:
            # ê°„ë‹¨í•œ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸
            results = train_model(
                model_type='simple',
                experiment_name=f'test_{create_timestamp()}',
                epochs=3,  # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì§§ê²Œ
                patience=2
            )
            
            print(f"\nâœ… í…ŒìŠ¤íŠ¸ í•™ìŠµ ì™„ë£Œ!")
            print(f"ì‹¤í—˜ ì´ë¦„: {results.get('experiment_name', 'Unknown')}")
            print(f"ì´ ì†Œìš” ì‹œê°„: {format_time(results.get('total_time', 0))}")
            
            if 'test_results' in results:
                print(f"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {results['test_results'].get('accuracy', 0):.4f}")
            
        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
    else:
        print("í…ŒìŠ¤íŠ¸ë¥¼ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
