def load_and_preprocess_csv(self, csv_path, window_size=50, stride=1):
        """CSV íŒŒì¼ ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        print(f"ğŸ“ ë°ì´í„° ë¡œë“œ: {csv_path}")
        
        # CSV ë¡œë“œ
        df = pd.read_csv(csv_path, encoding='utf-8')
        
        # íŠ¹ì§• ì»¬ëŸ¼ ì¶”ì¶œ
        feature_cols = [col for col in df.columns if col.startswith('feat_')]
        X = df[feature_cols].values
        y = df['label'].values if 'label' in df.columns else None
        
        print(f"   ì›ë³¸ ë°ì´í„°: {X.shape}")
        
        # ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì ìš©
        X_sequences = []
        y_sequences = []
        
        for i in range(0, len(X) - window_size + 1, stride):
            window_X = X[i:i + window_size]
            X_sequences.append(window_X)
            
            if y is not None:
                window_y = y[i:i + window_size]
                sequence_label = 1 if np.any(window_y == 1) else 0
                y_sequences.append(sequence_label)
        
        X_seq = np.array(X_sequences)
        y_seq = np.array(y_sequences) if y is not None else None
        
        # íŠ¹ì§• ìˆ˜ì— ë”°ë¥¸ ì •ê·œí™”
        original_shape = X_seq.shape
        X_2d = X_seq.reshape(-1, X_seq.shape[-1])
        
        # 256ê°œ íŠ¹ì§•ì´ë©´ 128ê°œë¡œ ì¶•ì†Œ (ëª¨ë¸ê³¼ ë§ì¶”ê¸°)
        if X_seq.shape[-1] > 128:
            print(f"   ğŸ“Š íŠ¹ì§• ì¶•ì†Œ: {X_seq.shape[-1]}ê°œ â†’ 128ê°œ")
            
            from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif
            
            # 1. ë¶„ì‚° ê¸°ë°˜ íŠ¹ì§• ì œê±°
            var_selector = VarianceThreshold(threshold=0.01)
            X_# í•™ìŠµëœ ëª¨ë¸ë¡œ ìƒˆë¡œìš´ ë°ì´í„° í…ŒìŠ¤íŠ¸
import numpy as np
import pandas as pd
from tensorflow.keras.models import load_model
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

class ModelTester:
    def __init__(self, model_path):
        """ëª¨ë¸ í…ŒìŠ¤í„° ì´ˆê¸°í™”"""
        try:
            # í˜¸í™˜ì„± ëª¨ë“œë¡œ ëª¨ë¸ ë¡œë“œ
            import tensorflow as tf
            self.model = tf.keras.models.load_model(model_path, compile=False)
            
            # ëª¨ë¸ ì¬ì»´íŒŒì¼
            self.model.compile(
                optimizer='adam',
                loss='binary_crossentropy',
                metrics=['accuracy']
            )
            
            print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
            print(f"ğŸ“Š ëª¨ë¸ ì…ë ¥ í˜•íƒœ: {self.model.input_shape}")
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("ğŸ’¡ í•´ê²° ë°©ë²•:")
            print("   1. python run_training.py ë¡œ ëª¨ë¸ì„ ë‹¤ì‹œ í•™ìŠµí•˜ì„¸ìš”")
            print("   2. ë˜ëŠ” ë‹¤ë¥¸ ëª¨ë¸ íŒŒì¼ì„ ì‚¬ìš©í•˜ì„¸ìš”")
            raise
        
        self.scaler = StandardScaler()
    
    def load_and_preprocess_csv(self, csv_path, window_size=50, stride=1):
        """CSV íŒŒì¼ ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        print(f"ğŸ“ ë°ì´í„° ë¡œë“œ: {csv_path}")
        
        # CSV ë¡œë“œ (ì¸ì½”ë”© ë¬¸ì œ ëŒ€ì‘)
        df = None
        encodings = ['utf-8', 'cp949', 'euc-kr', 'latin-1', 'utf-8-sig']
        
        for encoding in encodings:
            try:
                df = pd.read_csv(csv_path, encoding=encoding)
                print(f"   âœ… ì¸ì½”ë”© ì„±ê³µ: {encoding}")
                break
            except UnicodeDecodeError:
                continue
        
        if df is None:
            raise ValueError(f"ëª¨ë“  ì¸ì½”ë”© ì‹¤íŒ¨: {csv_path}")
        
        # íŠ¹ì§• ì»¬ëŸ¼ ì¶”ì¶œ
        feature_cols = [col for col in df.columns if col.startswith('feat_')]
        X = df[feature_cols].values
        y = df['label'].values if 'label' in df.columns else None
        
        print(f"   ì›ë³¸ ë°ì´í„°: {X.shape}")
        print(f"   ì›ë³¸ íŠ¹ì§• ìˆ˜: {len(feature_cols)}ê°œ")
        
        # ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì ìš©
        X_sequences = []
        y_sequences = []
        
        for i in range(0, len(X) - window_size + 1, stride):
            window_X = X[i:i + window_size]
            X_sequences.append(window_X)
            
            if y is not None:
                window_y = y[i:i + window_size]
                sequence_label = 1 if np.any(window_y == 1) else 0
                y_sequences.append(sequence_label)
        
        X_seq = np.array(X_sequences)
        y_seq = np.array(y_sequences) if y is not None else None
        
        print(f"   ìœˆë„ìš° ì ìš© í›„: {X_seq.shape}")
        
        # ëª¨ë¸ ì…ë ¥ ì°¨ì›ê³¼ ë§ì¶”ê¸°
        model_input_features = self.model.input_shape[-1]  # 128 ë˜ëŠ” 256
        current_features = X_seq.shape[-1]
        
        print(f"   ëª¨ë¸ ê¸°ëŒ€ íŠ¹ì§• ìˆ˜: {model_input_features}")
        print(f"   í˜„ì¬ ë°ì´í„° íŠ¹ì§• ìˆ˜: {current_features}")
        
        # ì°¨ì› ì¡°ì •
        if current_features != model_input_features:
            print(f"   ğŸ”§ íŠ¹ì§• ìˆ˜ ì¡°ì •: {current_features} â†’ {model_input_features}")
            
            if current_features > model_input_features:
                # íŠ¹ì§• ìˆ˜ ì¤„ì´ê¸° (256 â†’ 128)
                print(f"   ğŸ“Š íŠ¹ì§• ì„ íƒ ìˆ˜í–‰...")
                
                original_shape = X_seq.shape
                X_2d = X_seq.reshape(-1, X_seq.shape[-1])
                
                # 1. ë¶„ì‚° ê¸°ë°˜ íŠ¹ì§• ì œê±°
                from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif
                
                var_selector = VarianceThreshold(threshold=0.01)
                X_var = var_selector.fit_transform(X_2d)
                print(f"      ë¶„ì‚° ì œê±° í›„: {X_var.shape[1]}ê°œ")
                
                # 2. ìƒìœ„ íŠ¹ì§• ì„ íƒ
                if X_var.shape[1] > model_input_features:
                    temp_y = np.random.randint(0, 2, size=X_var.shape[0])
                    k_selector = SelectKBest(f_classif, k=model_input_features)
                    X_selected = k_selector.fit_transform(X_var, temp_y)
                    print(f"      ìµœì¢… ì„ íƒ: {X_selected.shape[1]}ê°œ")
                else:
                    X_selected = X_var
                
                # ì •ê·œí™”
                X_normalized = self.scaler.fit_transform(X_selected)
                
                # ì›ë³¸ í˜•íƒœë¡œ ë³µì›
                new_shape = (original_shape[0], original_shape[1], X_normalized.shape[1])
                X_seq = X_normalized.reshape(new_shape)
                
            elif current_features < model_input_features:
                # íŠ¹ì§• ìˆ˜ ëŠ˜ë¦¬ê¸° (íŒ¨ë”©)
                print(f"   ğŸ“Š íŠ¹ì§• íŒ¨ë”© ìˆ˜í–‰...")
                padding_size = model_input_features - current_features
                
                # ì œë¡œ íŒ¨ë”© ì¶”ê°€
                padding = np.zeros((X_seq.shape[0], X_seq.shape[1], padding_size))
                X_seq = np.concatenate([X_seq, padding], axis=-1)
                
                # ì •ê·œí™”
                original_shape = X_seq.shape
                X_2d = X_seq.reshape(-1, X_seq.shape[-1])
                X_normalized = self.scaler.fit_transform(X_2d)
                X_seq = X_normalized.reshape(original_shape)
        else:
            # ì°¨ì›ì´ ê°™ìœ¼ë©´ ì •ê·œí™”ë§Œ
            original_shape = X_seq.shape
            X_2d = X_seq.reshape(-1, X_seq.shape[-1])
            X_normalized = self.scaler.fit_transform(X_2d)
            X_seq = X_normalized.reshape(original_shape)
        
        print(f"   âœ… ìµœì¢… ë°ì´í„°: {X_seq.shape}")
        
        return X_seq, y_seq
    
    def predict_single_file(self, csv_path, threshold=0.5):
        """ë‹¨ì¼ íŒŒì¼ì— ëŒ€í•œ ì˜ˆì¸¡"""
        print(f"\nğŸ” íŒŒì¼ ë¶„ì„: {csv_path}")
        
        X_seq, y_true = self.load_and_preprocess_csv(csv_path)
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        predictions = self.model.predict(X_seq, verbose=0)
        y_pred_prob = predictions.flatten()
        y_pred = (y_pred_prob > threshold).astype(int)
        
        # ê²°ê³¼ ë¶„ì„
        fall_probability = np.mean(y_pred_prob)
        fall_count = np.sum(y_pred)
        total_windows = len(y_pred)
        
        print(f"ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼:")
        print(f"   - ì´ ìœˆë„ìš° ìˆ˜: {total_windows}")
        print(f"   - ë‚™ìƒ ê°ì§€ ìœˆë„ìš°: {fall_count}")
        print(f"   - í‰ê·  ë‚™ìƒ í™•ë¥ : {fall_probability:.3f}")
        print(f"   - ë‚™ìƒ ê°ì§€ ë¹„ìœ¨: {fall_count/total_windows*100:.1f}%")
        
        # ìµœì¢… íŒë‹¨
        if fall_count > total_windows * 0.3:  # 30% ì´ìƒ ë‚™ìƒìœ¼ë¡œ ê°ì§€ë˜ë©´
            final_prediction = "ğŸš¨ ë‚™ìƒ ê°ì§€!"
        elif fall_count > 0:
            final_prediction = "âš ï¸  ì˜ì‹¬ìŠ¤ëŸ¬ìš´ í™œë™"
        else:
            final_prediction = "âœ… ì •ìƒ í™œë™"
        
        print(f"ğŸ¯ ìµœì¢… íŒë‹¨: {final_prediction}")
        
        # ì‹¤ì œ ë¼ë²¨ì´ ìˆìœ¼ë©´ ì •í™•ë„ ê³„ì‚°
        if y_true is not None:
            accuracy = np.mean(y_pred == y_true)
            print(f"ğŸ“ˆ ì •í™•ë„: {accuracy:.3f}")
        
        return {
            'predictions': y_pred_prob,
            'binary_predictions': y_pred,
            'fall_probability': fall_probability,
            'fall_count': fall_count,
            'final_prediction': final_prediction
        }
    
    def batch_test(self, file_paths, threshold=0.5):
        """ì—¬ëŸ¬ íŒŒì¼ ì¼ê´„ í…ŒìŠ¤íŠ¸"""
        print(f"\nğŸ“‚ ì¼ê´„ í…ŒìŠ¤íŠ¸: {len(file_paths)}ê°œ íŒŒì¼")
        
        results = {}
        
        for file_path in file_paths:
            try:
                result = self.predict_single_file(file_path, threshold)
                results[file_path] = result
            except Exception as e:
                print(f"âŒ {file_path} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        
        # ì „ì²´ ê²°ê³¼ ìš”ì•½
        print(f"\nğŸ“‹ ì „ì²´ ê²°ê³¼ ìš”ì•½:")
        print("-" * 50)
        
        for file_path, result in results.items():
            filename = file_path.split('/')[-1]
            status = result['final_prediction']
            prob = result['fall_probability']
            print(f"{filename:20s} | {status:15s} | í™•ë¥ : {prob:.3f}")
        
        return results
    
    def create_prediction_plot(self, csv_path, threshold=0.5):
        """ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”"""
        X_seq, y_true = self.load_and_preprocess_csv(csv_path)
        predictions = self.model.predict(X_seq, verbose=0).flatten()
        
        plt.figure(figsize=(12, 6))
        
        # ì˜ˆì¸¡ í™•ë¥  í”Œë¡¯
        plt.subplot(2, 1, 1)
        plt.plot(predictions, label='ë‚™ìƒ í™•ë¥ ', color='red', alpha=0.7)
        plt.axhline(y=threshold, color='orange', linestyle='--', label=f'ì„ê³„ê°’ ({threshold})')
        plt.fill_between(range(len(predictions)), predictions, alpha=0.3, color='red')
        plt.ylabel('ë‚™ìƒ í™•ë¥ ')
        plt.title('ì‹œê°„ì— ë”°ë¥¸ ë‚™ìƒ ê°ì§€ í™•ë¥ ')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # ì´ì§„ ì˜ˆì¸¡ í”Œë¡¯
        plt.subplot(2, 1, 2)
        binary_pred = (predictions > threshold).astype(int)
        plt.plot(binary_pred, 'bo-', markersize=3, label='ë‚™ìƒ ê°ì§€')
        if y_true is not None:
            plt.plot(y_true, 'ro-', markersize=3, alpha=0.7, label='ì‹¤ì œ ë¼ë²¨')
        plt.ylabel('ë‚™ìƒ ê°ì§€')
        plt.xlabel('ì‹œê°„ ìœˆë„ìš°')
        plt.title('ë‚™ìƒ ê°ì§€ ê²°ê³¼')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()

# ì‚¬ìš© ì˜ˆì‹œ
def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸ§ª ë‚™ìƒ ê°ì§€ ëª¨ë¸ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # ëª¨ë¸ ë¡œë“œ
    model_path = "./models/csi_fall_detection_128features.h5"
    
    try:
        tester = ModelTester(model_path)
        
        # 1. ë‹¨ì¼ íŒŒì¼ í…ŒìŠ¤íŠ¸
        test_file = "./csi_data/case1/5_labeled.csv"
        result = tester.predict_single_file(test_file)
        
        # 2. ì‹œê°í™”
        tester.create_prediction_plot(test_file)
        
        # 3. ì—¬ëŸ¬ íŒŒì¼ ì¼ê´„ í…ŒìŠ¤íŠ¸
        test_files = [
            "./csi_data/case1/40.csv",
            "./csi_data/case2/4.csv",
            "./csi_data/case3/17_labeled.csv"
        ]
        batch_results = tester.batch_test(test_files)
        
    except FileNotFoundError:
        print("âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        print("   ë¨¼ì € run_training.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµì‹œì¼œì£¼ì„¸ìš”.")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    main()